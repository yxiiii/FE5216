{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from MonteCarlo import MonteCarlo\n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to check following arbitrage free conditions: For strike $K_i$, time to maturity $\\tau$\n",
    "$$ \\left(S_{0}-K_{i} e^{-r \\tau}\\right)^{+}<c_{0}<S_{0} $$\n",
    "$$ \\frac{C_{i, j}-C_{i-1, j}}{K_{i}-K_{i-1}} \\in [-1,0] $$\n",
    "$$ C_{i-1, j}-C_{i, j} \\geqslant \\frac{K_{i}-K_{i-1}}{K_{i+1}-K_{i}}\\left(C_{i, j}-C_{i+1, j}\\right) $$\n",
    "$$ C_{i, j+1}-C_{i, j} \\geq 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def arbitrage_check(data):\n",
    "#     cols = ['moneyness', 'tau', 'r', 'vol', 'C']\n",
    "#     data = pd.DataFrame(data, columns=cols)\n",
    "#     data['K'] = 1 / data['moneyness']\n",
    "#     data = data.sort_values(by='K')\n",
    "#     data['K-1'] = data['K'].shift(1)\n",
    "#     data['K+1'] = data['K'].shift(-1)\n",
    "#     data['C-1'] = data['C'].shift(1)\n",
    "#     data['C+1'] = data['C'].shift(-1)\n",
    "#     data = data.iloc[1:-1]\n",
    "#     # check 1\n",
    "#     data['check1'] = np.maximum(1 - data['K'] * np.exp(- data['r'] * data['tau']), 0)\n",
    "#     data = data.loc[(data['C'] < 1) & (data['C'] > data['check1'])] \n",
    "#     # check 2 \n",
    "#     data['check2'] = (data['C'] - data['C-1']) / (data['K'] - data['K-1'])\n",
    "#     data = data.loc[(data['check2'] >= -1) & (data['check2'] <= 0)]\n",
    "#     # check 3\n",
    "#     data['check3'] = (data['C'] - data['C-1']) / (data['C+1'] - data['C']) - (data['K'] - data['K-1']) / (data['K+1'] - data['K'])\n",
    "#     data = data.loc[data['check3'] >= 0]\n",
    "#     print(data)\n",
    "\n",
    "# data = pd.read_csv('test.csv')\n",
    "# data.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "# data = data[data['tau']==data['tau'][0]]\n",
    "# arbitrage_check(data.values.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=20>European call + GBM + Closed-form formula</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:05<00:00, 837.23it/s] \n",
      "100%|██████████| 5000/5000 [00:03<00:00, 1585.02it/s]\n",
      "100%|██████████| 5000/5000 [00:02<00:00, 1677.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       moneyness       tau         r       vol  option price\n",
      "3163    0.842777  0.533024  0.036294  0.187983      0.010036\n",
      "2028    0.921883  0.316636  0.077697  0.133479      0.010038\n",
      "12830   0.796456  0.483397  0.051270  0.240633      0.010107\n",
      "2070    0.846692  0.784535  0.039505  0.144355      0.010158\n",
      "4177    0.954340  0.387281  0.072730  0.071875      0.010169\n",
      "...          ...       ...       ...       ...           ...\n",
      "10493   1.254532  0.906340  0.076512  0.888865      0.430089\n",
      "412     1.292918  0.947030  0.030125  0.887099      0.431446\n",
      "10832   1.281616  0.918517  0.070999  0.876070      0.434199\n",
      "1691    1.248467  0.940501  0.076109  0.893988      0.435330\n",
      "12361   1.291263  0.949613  0.056372  0.893441      0.441792\n",
      "\n",
      "[13832 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "model = 'GBM' \n",
    "Type = 'European' \n",
    "option = 'call' \n",
    "\n",
    "American = False if Type == 'European' else True\n",
    "optionType = 'c' if option == 'call' else 'p'\n",
    "\n",
    "cols = ['moneyness', 'tau', 'r', 'vol', 'option price']\n",
    "data = []\n",
    "\n",
    "while len(data) < 10000:\n",
    "    for i in tqdm(range(5000)):\n",
    "        vol = random.uniform(0.02, 0.9)\n",
    "        r = random.uniform(0.03, 0.08)\n",
    "        tau = random.uniform(0.3, 0.95)\n",
    "        moneyness = random.uniform(0.7, 1.3)\n",
    "        K = 1 / moneyness\n",
    "        MC = MonteCarlo(model='GBM', S0=1, K=K, T=tau, r=r, q=0, v=vol, method='formula')\n",
    "        MC.generate_S(1000,10)\n",
    "        option_price = MC.pricer(optionType=optionType, American=American)\n",
    "        if option_price > 0.01:\n",
    "            data.append([moneyness, tau, r, vol, option_price])\n",
    "\n",
    "data = pd.DataFrame(data, columns=cols)\n",
    "data.to_csv(f'data_{model}_{Type}_{option}.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moneyness</th>\n",
       "      <th>tau</th>\n",
       "      <th>r</th>\n",
       "      <th>vol</th>\n",
       "      <th>option price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9268</th>\n",
       "      <td>0.721101</td>\n",
       "      <td>0.307023</td>\n",
       "      <td>0.078133</td>\n",
       "      <td>0.398930</td>\n",
       "      <td>0.010013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>0.891375</td>\n",
       "      <td>0.572469</td>\n",
       "      <td>0.073761</td>\n",
       "      <td>0.114388</td>\n",
       "      <td>0.010030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7260</th>\n",
       "      <td>0.837894</td>\n",
       "      <td>0.878324</td>\n",
       "      <td>0.038886</td>\n",
       "      <td>0.140775</td>\n",
       "      <td>0.010066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>0.748879</td>\n",
       "      <td>0.352308</td>\n",
       "      <td>0.063310</td>\n",
       "      <td>0.340839</td>\n",
       "      <td>0.010068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>0.901987</td>\n",
       "      <td>0.700607</td>\n",
       "      <td>0.056933</td>\n",
       "      <td>0.095568</td>\n",
       "      <td>0.010080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>1.266673</td>\n",
       "      <td>0.890929</td>\n",
       "      <td>0.072211</td>\n",
       "      <td>0.865899</td>\n",
       "      <td>0.423184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12907</th>\n",
       "      <td>1.295607</td>\n",
       "      <td>0.848782</td>\n",
       "      <td>0.070777</td>\n",
       "      <td>0.864142</td>\n",
       "      <td>0.423604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>1.295815</td>\n",
       "      <td>0.913508</td>\n",
       "      <td>0.058887</td>\n",
       "      <td>0.841988</td>\n",
       "      <td>0.423890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8591</th>\n",
       "      <td>1.262412</td>\n",
       "      <td>0.936385</td>\n",
       "      <td>0.079033</td>\n",
       "      <td>0.858610</td>\n",
       "      <td>0.429410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>1.241392</td>\n",
       "      <td>0.934702</td>\n",
       "      <td>0.079153</td>\n",
       "      <td>0.895006</td>\n",
       "      <td>0.433697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13890 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       moneyness       tau         r       vol  option price\n",
       "9268    0.721101  0.307023  0.078133  0.398930      0.010013\n",
       "4986    0.891375  0.572469  0.073761  0.114388      0.010030\n",
       "7260    0.837894  0.878324  0.038886  0.140775      0.010066\n",
       "3441    0.748879  0.352308  0.063310  0.340839      0.010068\n",
       "4235    0.901987  0.700607  0.056933  0.095568      0.010080\n",
       "...          ...       ...       ...       ...           ...\n",
       "823     1.266673  0.890929  0.072211  0.865899      0.423184\n",
       "12907   1.295607  0.848782  0.070777  0.864142      0.423604\n",
       "711     1.295815  0.913508  0.058887  0.841988      0.423890\n",
       "8591    1.262412  0.936385  0.079033  0.858610      0.429410\n",
       "9688    1.241392  0.934702  0.079153  0.895006      0.433697\n",
       "\n",
       "[13890 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values(by='option price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moneyness</th>\n",
       "      <th>tau</th>\n",
       "      <th>r</th>\n",
       "      <th>vol</th>\n",
       "      <th>option price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10537.000000</td>\n",
       "      <td>10537.000000</td>\n",
       "      <td>10537.000000</td>\n",
       "      <td>10537.000000</td>\n",
       "      <td>10537.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.063708</td>\n",
       "      <td>0.643051</td>\n",
       "      <td>0.055380</td>\n",
       "      <td>0.542235</td>\n",
       "      <td>0.218922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.157691</td>\n",
       "      <td>0.184528</td>\n",
       "      <td>0.014396</td>\n",
       "      <td>0.237476</td>\n",
       "      <td>0.071644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700032</td>\n",
       "      <td>0.300022</td>\n",
       "      <td>0.030001</td>\n",
       "      <td>0.020041</td>\n",
       "      <td>0.100056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.949484</td>\n",
       "      <td>0.488232</td>\n",
       "      <td>0.043024</td>\n",
       "      <td>0.362569</td>\n",
       "      <td>0.160809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.087720</td>\n",
       "      <td>0.650307</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.578912</td>\n",
       "      <td>0.215439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.194842</td>\n",
       "      <td>0.802350</td>\n",
       "      <td>0.067763</td>\n",
       "      <td>0.740467</td>\n",
       "      <td>0.267869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.299951</td>\n",
       "      <td>0.949958</td>\n",
       "      <td>0.079999</td>\n",
       "      <td>0.899886</td>\n",
       "      <td>0.430429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          moneyness           tau             r           vol  option price\n",
       "count  10537.000000  10537.000000  10537.000000  10537.000000  10537.000000\n",
       "mean       1.063708      0.643051      0.055380      0.542235      0.218922\n",
       "std        0.157691      0.184528      0.014396      0.237476      0.071644\n",
       "min        0.700032      0.300022      0.030001      0.020041      0.100056\n",
       "25%        0.949484      0.488232      0.043024      0.362569      0.160809\n",
       "50%        1.087720      0.650307      0.055603      0.578912      0.215439\n",
       "75%        1.194842      0.802350      0.067763      0.740467      0.267869\n",
       "max        1.299951      0.949958      0.079999      0.899886      0.430429"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.071, test=0.070) MSE: (train=0.000, test=0.000) r2: (train=0.942, test=0.943) total time=   1.6s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.068, test=0.068) MSE: (train=0.000, test=0.000) r2: (train=0.942, test=0.942) total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.068, test=0.068) MSE: (train=0.000, test=0.000) r2: (train=0.945, test=0.945) total time=   5.1s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.011, test=0.011) MAPE: (train=0.059, test=0.058) MSE: (train=0.000, test=0.000) r2: (train=0.947, test=0.947) total time=   4.7s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.067, test=0.067) MSE: (train=0.000, test=0.000) r2: (train=0.941, test=0.941) total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.011, test=0.012) MAPE: (train=0.061, test=0.064) MSE: (train=0.000, test=0.000) r2: (train=0.954, test=0.953) total time=   5.1s\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.066, test=0.065) MSE: (train=0.000, test=0.000) r2: (train=0.941, test=0.943) total time=   1.5s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.014, test=0.013) MAPE: (train=0.074, test=0.073) MSE: (train=0.000, test=0.000) r2: (train=0.942, test=0.943) total time=   3.8s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.068, test=0.067) MSE: (train=0.000, test=0.000) r2: (train=0.943, test=0.941) total time=   2.5s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.066, test=0.067) MSE: (train=0.000, test=0.000) r2: (train=0.941, test=0.941) total time=   1.4s\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.014) MAPE: (train=0.071, test=0.073) MSE: (train=0.000, test=0.000) r2: (train=0.941, test=0.941) total time=   4.2s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.023, test=0.022) MAPE: (train=0.123, test=0.121) MSE: (train=0.001, test=0.001) r2: (train=0.870, test=0.874) total time=   1.9s\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.066, test=0.065) MSE: (train=0.000, test=0.000) r2: (train=0.938, test=0.940) total time=   2.4s\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.014, test=0.014) MAPE: (train=0.074, test=0.076) MSE: (train=0.000, test=0.000) r2: (train=0.940, test=0.939) total time=   5.4s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.014, test=0.014) MAPE: (train=0.075, test=0.075) MSE: (train=0.000, test=0.000) r2: (train=0.939, test=0.939) total time=   4.9s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.069, test=0.068) MSE: (train=0.000, test=0.000) r2: (train=0.943, test=0.941) total time=   7.8s\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.014, test=0.014) MAPE: (train=0.073, test=0.073) MSE: (train=0.000, test=0.000) r2: (train=0.940, test=0.941) total time=   4.3s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.012) MAPE: (train=0.066, test=0.066) MSE: (train=0.000, test=0.000) r2: (train=0.941, test=0.942) total time=   4.6s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.016, test=0.016) MAPE: (train=0.085, test=0.085) MSE: (train=0.000, test=0.000) r2: (train=0.930, test=0.927) total time=   4.0s\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.014) MAPE: (train=0.071, test=0.073) MSE: (train=0.000, test=0.000) r2: (train=0.941, test=0.941) total time=   3.2s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.069, test=0.069) MSE: (train=0.000, test=0.000) r2: (train=0.942, test=0.942) total time=   8.9s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.067, test=0.066) MSE: (train=0.000, test=0.000) r2: (train=0.941, test=0.942) total time=   9.5s\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.014, test=0.014) MAPE: (train=0.078, test=0.078) MSE: (train=0.000, test=0.000) r2: (train=0.937, test=0.937) total time=  14.2s\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.066, test=0.068) MSE: (train=0.000, test=0.000) r2: (train=0.941, test=0.940) total time=   8.9s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.014, test=0.013) MAPE: (train=0.073, test=0.073) MSE: (train=0.000, test=0.000) r2: (train=0.940, test=0.938) total time=  12.1s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.066, test=0.065) MSE: (train=0.000, test=0.000) r2: (train=0.938, test=0.938) total time=  47.5s\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.067, test=0.066) MSE: (train=0.000, test=0.000) r2: (train=0.939, test=0.941) total time=  49.7s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.066, test=0.066) MSE: (train=0.000, test=0.000) r2: (train=0.940, test=0.940) total time=  57.7s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.012, test=0.012) MAPE: (train=0.065, test=0.065) MSE: (train=0.000, test=0.000) r2: (train=0.942, test=0.942) total time=   2.5s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.011, test=0.011) MAPE: (train=0.059, test=0.059) MSE: (train=0.000, test=0.000) r2: (train=0.957, test=0.956) total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.028, test=0.028) MSE: (train=0.000, test=0.000) r2: (train=0.991, test=0.991) total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.029, test=0.029) MSE: (train=0.000, test=0.000) r2: (train=0.991, test=0.991) total time=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.023, test=0.023) MSE: (train=0.000, test=0.000) r2: (train=0.994, test=0.994) total time=   8.1s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.069, test=0.068) MSE: (train=0.000, test=0.000) r2: (train=0.942, test=0.940) total time=  51.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.008, test=0.008) MAPE: (train=0.048, test=0.047) MSE: (train=0.000, test=0.000) r2: (train=0.975, test=0.974) total time=  11.9s\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.014, test=0.014) MAPE: (train=0.075, test=0.077) MSE: (train=0.000, test=0.000) r2: (train=0.938, test=0.938) total time=  52.0s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.012) MAPE: (train=0.066, test=0.065) MSE: (train=0.000, test=0.000) r2: (train=0.942, test=0.940) total time=   2.2s\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.065, test=0.066) MSE: (train=0.000, test=0.000) r2: (train=0.937, test=0.937) total time=   1.7s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.012, test=0.012) MAPE: (train=0.063, test=0.062) MSE: (train=0.000, test=0.000) r2: (train=0.943, test=0.943) total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.006, test=0.006) MAPE: (train=0.031, test=0.032) MSE: (train=0.000, test=0.000) r2: (train=0.989, test=0.989) total time=  10.6s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.012, test=0.013) MAPE: (train=0.065, test=0.065) MSE: (train=0.000, test=0.000) r2: (train=0.941, test=0.941) total time=   4.4s\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.065, test=0.065) MSE: (train=0.000, test=0.000) r2: (train=0.938, test=0.940) total time=   3.0s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.014, test=0.013) MAPE: (train=0.074, test=0.073) MSE: (train=0.000, test=0.000) r2: (train=0.940, test=0.941) total time=   6.2s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.071, test=0.071) MSE: (train=0.000, test=0.000) r2: (train=0.942, test=0.940) total time=   3.9s\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.014, test=0.014) MAPE: (train=0.075, test=0.077) MSE: (train=0.000, test=0.000) r2: (train=0.938, test=0.937) total time=   2.4s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(64, 64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.012) MAPE: (train=0.066, test=0.065) MSE: (train=0.000, test=0.000) r2: (train=0.941, test=0.941) total time=   6.1s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(64, 64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.014, test=0.014) MAPE: (train=0.076, test=0.076) MSE: (train=0.000, test=0.000) r2: (train=0.938, test=0.938) total time=   7.9s\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(64, 64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.068, test=0.068) MSE: (train=0.000, test=0.000) r2: (train=0.942, test=0.944) total time=   9.5s\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(64, 64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.014, test=0.014) MAPE: (train=0.069, test=0.071) MSE: (train=0.000, test=0.000) r2: (train=0.927, test=0.927) total time=   4.4s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(64, 64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.067, test=0.066) MSE: (train=0.000, test=0.000) r2: (train=0.935, test=0.932) total time=   5.5s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(128, 128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.059, test=0.058) MAPE: (train=0.312, test=0.302) MSE: (train=0.005, test=0.005) r2: (train=0.001, test=-0.000) total time=   5.3s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(128, 128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.014, test=0.014) MAPE: (train=0.073, test=0.073) MSE: (train=0.000, test=0.000) r2: (train=0.937, test=0.938) total time=  24.5s\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(128, 128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.072, test=0.072) MSE: (train=0.000, test=0.000) r2: (train=0.941, test=0.942) total time=  24.5s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(128, 128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.067, test=0.067) MSE: (train=0.000, test=0.000) r2: (train=0.930, test=0.928) total time=  22.3s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(256, 256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.060, test=0.059) MAPE: (train=0.325, test=0.315) MSE: (train=0.005, test=0.005) r2: (train=-0.004, test=-0.002) total time=  17.7s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(256, 256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.059, test=0.059) MAPE: (train=0.309, test=0.314) MSE: (train=0.005, test=0.005) r2: (train=-0.005, test=-0.003) total time=  19.2s\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(128, 128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.014) MAPE: (train=0.072, test=0.074) MSE: (train=0.000, test=0.000) r2: (train=0.941, test=0.941) total time=  26.2s\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(256, 256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.060, test=0.059) MAPE: (train=0.325, test=0.323) MSE: (train=0.005, test=0.005) r2: (train=-0.005, test=-0.005) total time=  14.8s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(256, 256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.060, test=0.059) MAPE: (train=0.322, test=0.319) MSE: (train=0.005, test=0.005) r2: (train=-0.003, test=-0.003) total time=  15.5s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(8, 8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.071, test=0.071) MSE: (train=0.000, test=0.000) r2: (train=0.942, test=0.942) total time=   3.4s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(8, 8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.059, test=0.060) MAPE: (train=0.316, test=0.323) MSE: (train=0.005, test=0.005) r2: (train=0.000, test=-0.002) total time=   1.0s\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(256, 256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.059, test=0.061) MAPE: (train=0.316, test=0.324) MSE: (train=0.005, test=0.005) r2: (train=-0.002, test=-0.002) total time=  17.9s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(8, 8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.028, test=0.027) MSE: (train=0.000, test=0.000) r2: (train=0.991, test=0.992) total time=   8.3s\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(8, 8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.003, test=0.003) MAPE: (train=0.019, test=0.018) MSE: (train=0.000, test=0.000) r2: (train=0.996, test=0.996) total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(8, 8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.011, test=0.012) MAPE: (train=0.059, test=0.061) MSE: (train=0.000, test=0.000) r2: (train=0.957, test=0.956) total time=   8.3s\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(16, 16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.014, test=0.014) MAPE: (train=0.076, test=0.076) MSE: (train=0.000, test=0.000) r2: (train=0.939, test=0.939) total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(16, 16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.022, test=0.021) MSE: (train=0.000, test=0.000) r2: (train=0.995, test=0.995) total time=  13.4s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(16, 16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.021, test=0.022) MSE: (train=0.000, test=0.000) r2: (train=0.995, test=0.995) total time=  13.3s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(32, 32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.060, test=0.059) MAPE: (train=0.328, test=0.318) MSE: (train=0.005, test=0.005) r2: (train=-0.004, test=-0.001) total time=   0.9s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(16, 16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.015, test=0.015) MAPE: (train=0.082, test=0.082) MSE: (train=0.000, test=0.000) r2: (train=0.934, test=0.933) total time=   4.9s\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(32, 32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.016, test=0.016) MAPE: (train=0.087, test=0.088) MSE: (train=0.000, test=0.000) r2: (train=0.927, test=0.927) total time=   4.4s\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(16, 16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.012, test=0.012) MAPE: (train=0.060, test=0.061) MSE: (train=0.000, test=0.000) r2: (train=0.944, test=0.944) total time=   6.7s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(32, 32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.066, test=0.066) MSE: (train=0.000, test=0.000) r2: (train=0.931, test=0.929) total time=   5.3s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(64, 64, 64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.014, test=0.014) MAPE: (train=0.070, test=0.071) MSE: (train=0.000, test=0.000) r2: (train=0.921, test=0.920) total time=   7.1s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(32, 32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.006, test=0.007) MAPE: (train=0.035, test=0.036) MSE: (train=0.000, test=0.000) r2: (train=0.987, test=0.986) total time=  19.7s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(64, 64, 64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.012) MAPE: (train=0.066, test=0.065) MSE: (train=0.000, test=0.000) r2: (train=0.939, test=0.939) total time=   9.2s\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(64, 64, 64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.066, test=0.065) MSE: (train=0.000, test=0.000) r2: (train=0.941, test=0.942) total time=   9.7s\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(32, 32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.024, test=0.024) MSE: (train=0.000, test=0.000) r2: (train=0.994, test=0.994) total time=  24.6s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(64, 64, 64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.069, test=0.068) MSE: (train=0.000, test=0.000) r2: (train=0.942, test=0.941) total time=  10.0s\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(64, 64, 64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.016, test=0.016) MAPE: (train=0.075, test=0.075) MSE: (train=0.000, test=0.000) r2: (train=0.911, test=0.913) total time=  12.7s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(128, 128, 128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.014, test=0.014) MAPE: (train=0.073, test=0.073) MSE: (train=0.000, test=0.000) r2: (train=0.939, test=0.939) total time=  19.4s\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(128, 128, 128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.060, test=0.059) MAPE: (train=0.319, test=0.318) MSE: (train=0.005, test=0.005) r2: (train=0.001, test=0.001) total time=   8.3s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(128, 128, 128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.060, test=0.059) MAPE: (train=0.320, test=0.317) MSE: (train=0.005, test=0.005) r2: (train=-0.001, test=-0.001) total time=   6.7s\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(256, 256, 256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.060, test=0.059) MAPE: (train=0.318, test=0.309) MSE: (train=0.005, test=0.005) r2: (train=-0.000, test=0.000) total time=  19.3s\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(128, 128, 128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.017, test=0.018) MAPE: (train=0.095, test=0.097) MSE: (train=0.000, test=0.000) r2: (train=0.916, test=0.917) total time=  26.4s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(128, 128, 128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.012, test=0.012) MAPE: (train=0.064, test=0.064) MSE: (train=0.000, test=0.000) r2: (train=0.940, test=0.940) total time=  46.2s\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(256, 256, 256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.060, test=0.061) MAPE: (train=0.331, test=0.339) MSE: (train=0.005, test=0.005) r2: (train=-0.017, test=-0.026) total time=  23.4s\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(256, 256, 256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.059, test=0.059) MAPE: (train=0.310, test=0.309) MSE: (train=0.005, test=0.005) r2: (train=-0.003, test=-0.003) total time=  26.0s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.021, test=0.021) MSE: (train=0.000, test=0.000) r2: (train=0.995, test=0.995) total time=   4.3s\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(256, 256, 256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.060, test=0.059) MAPE: (train=0.321, test=0.318) MSE: (train=0.005, test=0.005) r2: (train=-0.002, test=-0.002) total time=  25.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.024, test=0.025) MSE: (train=0.000, test=0.000) r2: (train=0.993, test=0.992) total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.009, test=0.009) MAPE: (train=0.048, test=0.046) MSE: (train=0.000, test=0.000) r2: (train=0.972, test=0.974) total time=   7.3s\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(256, 256, 256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.059, test=0.061) MAPE: (train=0.322, test=0.330) MSE: (train=0.005, test=0.005) r2: (train=-0.005, test=-0.003) total time=  23.4s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.025, test=0.024) MSE: (train=0.000, test=0.000) r2: (train=0.993, test=0.994) total time=   9.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.021, test=0.021) MSE: (train=0.000, test=0.000) r2: (train=0.995, test=0.995) total time=   9.4s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.006, test=0.006) MAPE: (train=0.031, test=0.031) MSE: (train=0.000, test=0.000) r2: (train=0.990, test=0.989) total time=   3.2s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.019, test=0.019) MSE: (train=0.000, test=0.000) r2: (train=0.996, test=0.996) total time=   3.0s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.027, test=0.026) MSE: (train=0.000, test=0.000) r2: (train=0.993, test=0.993) total time=   4.6s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.003, test=0.003) MAPE: (train=0.016, test=0.017) MSE: (train=0.000, test=0.000) r2: (train=0.997, test=0.997) total time=   8.1s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.024, test=0.024) MSE: (train=0.000, test=0.000) r2: (train=0.994, test=0.993) total time=   3.6s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.020, test=0.020) MSE: (train=0.000, test=0.000) r2: (train=0.996, test=0.996) total time=   9.9s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.025, test=0.025) MSE: (train=0.000, test=0.000) r2: (train=0.993, test=0.993) total time=   5.1s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.003, test=0.003) MAPE: (train=0.018, test=0.019) MSE: (train=0.000, test=0.000) r2: (train=0.996, test=0.996) total time=   9.8s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.003, test=0.003) MAPE: (train=0.018, test=0.019) MSE: (train=0.000, test=0.000) r2: (train=0.996, test=0.996) total time=   6.9s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.006, test=0.006) MAPE: (train=0.032, test=0.032) MSE: (train=0.000, test=0.000) r2: (train=0.990, test=0.990) total time=  10.3s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.008, test=0.008) MAPE: (train=0.038, test=0.039) MSE: (train=0.000, test=0.000) r2: (train=0.986, test=0.986) total time=  12.8s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.023, test=0.025) MSE: (train=0.000, test=0.000) r2: (train=0.994, test=0.993) total time=   9.7s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.024, test=0.023) MSE: (train=0.000, test=0.000) r2: (train=0.994, test=0.994) total time=   9.2s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.021, test=0.021) MSE: (train=0.000, test=0.000) r2: (train=0.995, test=0.995) total time=  16.9s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.023, test=0.024) MSE: (train=0.000, test=0.000) r2: (train=0.994, test=0.994) total time=  14.5s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.008, test=0.008) MAPE: (train=0.043, test=0.043) MSE: (train=0.000, test=0.000) r2: (train=0.983, test=0.983) total time=  37.7s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.021, test=0.021) MSE: (train=0.000, test=0.000) r2: (train=0.995, test=0.995) total time=  47.3s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.003, test=0.004) MAPE: (train=0.019, test=0.020) MSE: (train=0.000, test=0.000) r2: (train=0.996, test=0.995) total time=  51.8s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.021, test=0.020) MSE: (train=0.000, test=0.000) r2: (train=0.995, test=0.995) total time=  29.5s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.006, test=0.006) MAPE: (train=0.029, test=0.028) MSE: (train=0.000, test=0.000) r2: (train=0.992, test=0.992) total time=  47.0s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.012, test=0.012) MAPE: (train=0.066, test=0.065) MSE: (train=0.000, test=0.000) r2: (train=0.943, test=0.943) total time=  58.2s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.030, test=0.029) MSE: (train=0.000, test=0.000) r2: (train=0.991, test=0.991) total time= 2.3min\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.029, test=0.029) MSE: (train=0.000, test=0.000) r2: (train=0.991, test=0.990) total time= 2.1min\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.023, test=0.022) MSE: (train=0.000, test=0.000) r2: (train=0.994, test=0.993) total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.023, test=0.025) MSE: (train=0.000, test=0.000) r2: (train=0.994, test=0.993) total time=  14.1s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.022, test=0.022) MSE: (train=0.000, test=0.000) r2: (train=0.995, test=0.994) total time=   5.6s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.024, test=0.023) MSE: (train=0.000, test=0.000) r2: (train=0.994, test=0.994) total time=   8.0s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.023, test=0.023) MSE: (train=0.000, test=0.000) r2: (train=0.994, test=0.995) total time=   7.1s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.006, test=0.006) MAPE: (train=0.030, test=0.029) MSE: (train=0.000, test=0.000) r2: (train=0.991, test=0.991) total time=   5.5s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.006, test=0.006) MAPE: (train=0.029, test=0.030) MSE: (train=0.000, test=0.000) r2: (train=0.991, test=0.990) total time=   2.1s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.022, test=0.022) MSE: (train=0.000, test=0.000) r2: (train=0.995, test=0.995) total time=   3.4s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.024, test=0.023) MSE: (train=0.000, test=0.000) r2: (train=0.994, test=0.994) total time=   3.3s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.013, test=0.013) MAPE: (train=0.068, test=0.070) MSE: (train=0.000, test=0.000) r2: (train=0.944, test=0.943) total time= 1.4min\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.023, test=0.023) MSE: (train=0.000, test=0.000) r2: (train=0.994, test=0.994) total time=   3.0s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.028, test=0.029) MSE: (train=0.000, test=0.000) r2: (train=0.992, test=0.991) total time=   6.0s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.003, test=0.003) MAPE: (train=0.016, test=0.016) MSE: (train=0.000, test=0.000) r2: (train=0.997, test=0.997) total time=   8.2s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.008, test=0.008) MAPE: (train=0.038, test=0.038) MSE: (train=0.000, test=0.000) r2: (train=0.986, test=0.986) total time=   5.4s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.003, test=0.003) MAPE: (train=0.014, test=0.014) MSE: (train=0.000, test=0.000) r2: (train=0.998, test=0.998) total time=   9.6s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.009, test=0.009) MAPE: (train=0.046, test=0.046) MSE: (train=0.000, test=0.000) r2: (train=0.979, test=0.980) total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.028, test=0.027) MSE: (train=0.000, test=0.000) r2: (train=0.992, test=0.992) total time= 2.9min\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(64, 64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.002, test=0.002) MAPE: (train=0.012, test=0.013) MSE: (train=0.000, test=0.000) r2: (train=0.998, test=0.998) total time=  23.3s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(64, 64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.003, test=0.003) MAPE: (train=0.017, test=0.017) MSE: (train=0.000, test=0.000) r2: (train=0.997, test=0.996) total time=  27.1s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(64, 64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.027, test=0.027) MSE: (train=0.000, test=0.000) r2: (train=0.993, test=0.993) total time=  25.4s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(64, 64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.025, test=0.026) MSE: (train=0.000, test=0.000) r2: (train=0.994, test=0.994) total time=  18.4s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(64, 64, 64), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.003, test=0.002) MAPE: (train=0.014, test=0.013) MSE: (train=0.000, test=0.000) r2: (train=0.998, test=0.998) total time=  31.5s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(128, 128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.003, test=0.003) MAPE: (train=0.015, test=0.015) MSE: (train=0.000, test=0.000) r2: (train=0.997, test=0.997) total time= 1.4min\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(128, 128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.021, test=0.022) MSE: (train=0.000, test=0.000) r2: (train=0.995, test=0.994) total time= 1.6min\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(128, 128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.003, test=0.003) MAPE: (train=0.018, test=0.018) MSE: (train=0.000, test=0.000) r2: (train=0.996, test=0.996) total time= 1.5min\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(128, 128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.023, test=0.023) MSE: (train=0.000, test=0.000) r2: (train=0.995, test=0.995) total time= 1.1min\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(128, 128, 128), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.019, test=0.019) MSE: (train=0.000, test=0.000) r2: (train=0.996, test=0.996) total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(256, 256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.003, test=0.003) MAPE: (train=0.017, test=0.017) MSE: (train=0.000, test=0.000) r2: (train=0.997, test=0.996) total time= 5.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(256, 256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.020, test=0.021) MSE: (train=0.000, test=0.000) r2: (train=0.996, test=0.995) total time= 5.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lusihan/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(256, 256, 256), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.003, test=0.003) MAPE: (train=0.018, test=0.018) MSE: (train=0.000, test=0.000) r2: (train=0.996, test=0.996) total time= 5.8min\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(8, 8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.002, test=0.002) MAPE: (train=0.013, test=0.013) MSE: (train=0.000, test=0.000) r2: (train=0.998, test=0.998) total time=   6.7s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(8, 8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.026, test=0.027) MSE: (train=0.000, test=0.000) r2: (train=0.992, test=0.991) total time=   4.4s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(8, 8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.024, test=0.023) MSE: (train=0.000, test=0.000) r2: (train=0.993, test=0.993) total time=   4.4s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(8, 8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.004, test=0.004) MAPE: (train=0.023, test=0.022) MSE: (train=0.000, test=0.000) r2: (train=0.994, test=0.994) total time=   2.8s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(8, 8, 8, 8), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.007, test=0.007) MAPE: (train=0.038, test=0.039) MSE: (train=0.000, test=0.000) r2: (train=0.986, test=0.987) total time=   5.0s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(16, 16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.009, test=0.009) MAPE: (train=0.045, test=0.046) MSE: (train=0.000, test=0.000) r2: (train=0.980, test=0.979) total time=   3.2s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(16, 16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.003, test=0.004) MAPE: (train=0.020, test=0.021) MSE: (train=0.000, test=0.000) r2: (train=0.996, test=0.995) total time=   6.2s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(16, 16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.027, test=0.027) MSE: (train=0.000, test=0.000) r2: (train=0.992, test=0.992) total time=   4.4s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(16, 16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.007, test=0.007) MAPE: (train=0.035, test=0.035) MSE: (train=0.000, test=0.000) r2: (train=0.989, test=0.989) total time=   5.5s\n",
      "[CV 5/5] END activation=tanh, hidden_layer_sizes=(16, 16, 16, 16), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.005, test=0.005) MAPE: (train=0.025, test=0.025) MSE: (train=0.000, test=0.000) r2: (train=0.993, test=0.994) total time=   9.9s\n",
      "[CV 1/5] END activation=tanh, hidden_layer_sizes=(32, 32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.006, test=0.006) MAPE: (train=0.031, test=0.030) MSE: (train=0.000, test=0.000) r2: (train=0.992, test=0.992) total time=   7.7s\n",
      "[CV 2/5] END activation=tanh, hidden_layer_sizes=(32, 32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.006, test=0.006) MAPE: (train=0.030, test=0.031) MSE: (train=0.000, test=0.000) r2: (train=0.991, test=0.991) total time=  20.1s\n",
      "[CV 3/5] END activation=tanh, hidden_layer_sizes=(32, 32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.006, test=0.006) MAPE: (train=0.035, test=0.034) MSE: (train=0.000, test=0.000) r2: (train=0.988, test=0.988) total time=  11.2s\n",
      "[CV 4/5] END activation=tanh, hidden_layer_sizes=(32, 32, 32, 32), learning_rate_init=0.005, max_iter=500, solver=adam; MAE: (train=0.002, test=0.002) MAPE: (train=0.013, test=0.013) MSE: (train=0.000, test=0.000) r2: (train=0.998, test=0.998) total time=  15.9s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lusihan/Desktop/FE5216/train.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lusihan/Desktop/FE5216/train.ipynb#ch0000011?line=21'>22</a>\u001b[0m MLP \u001b[39m=\u001b[39m MLPRegressor(hidden_layer_sizes\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m8\u001b[39m), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m, learning_rate_init\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m, max_iter\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, tol\u001b[39m=\u001b[39m\u001b[39m1e-10\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, validation_fraction\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lusihan/Desktop/FE5216/train.ipynb#ch0000011?line=22'>23</a>\u001b[0m search \u001b[39m=\u001b[39m GridSearchCV(MLP, param_grid\u001b[39m=\u001b[39mparam_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring \u001b[39m=\u001b[39m scoring, refit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMSE\u001b[39m\u001b[39m'\u001b[39m, return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lusihan/Desktop/FE5216/train.ipynb#ch0000011?line=23'>24</a>\u001b[0m search\u001b[39m.\u001b[39;49mfit(x,y)\n",
      "File \u001b[0;32m~/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    893\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1391\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1392\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/Desktop/env/TBIC/lib/python3.9/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    839\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m         clone(base_estimator),\n\u001b[1;32m    841\u001b[0m         X,\n\u001b[1;32m    842\u001b[0m         y,\n\u001b[1;32m    843\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    844\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    845\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    846\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    847\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    848\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    849\u001b[0m     )\n\u001b[1;32m    850\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    851\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    852\u001b[0m     )\n\u001b[1;32m    853\u001b[0m )\n\u001b[1;32m    855\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/env/TBIC/lib/python3.9/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/Desktop/env/TBIC/lib/python3.9/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/Desktop/env/TBIC/lib/python3.9/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(f'data_{model}_{Type}_{option}.csv')\n",
    "\n",
    "x = data[['moneyness', 'tau', 'r', 'vol']]\n",
    "y = data['option price']\n",
    "\n",
    "scoring = {\n",
    "    'r2':'r2', \n",
    "    'MSE': make_scorer(mean_squared_error),\n",
    "    'MAPE': make_scorer(mean_absolute_percentage_error),\n",
    "    'MAE': make_scorer(mean_absolute_error),    \n",
    "    }\n",
    "param_grid = {\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'hidden_layer_sizes': \n",
    "        [(2 ** i, 2 ** i) for i in np.arange(3, 7)] + \n",
    "        [(2 ** i, 2 ** i, 2 ** i) for i in np.arange(3, 7)] + \n",
    "        [(2 ** i, 2 ** i, 2 ** i, 2 ** i) for i in np.arange(3, 7)],\n",
    "    'max_iter': [500],\n",
    "    'learning_rate_init': np.arange(0.005, 0.005+0.001, 0.001),\n",
    "}\n",
    "MLP = MLPRegressor(hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', batch_size=1024, learning_rate_init=0.02, max_iter=500, tol=1e-10, shuffle=True, verbose=False, validation_fraction=0.1)\n",
    "search = GridSearchCV(MLP, param_grid=param_grid, cv=5, scoring = scoring, refit='MSE', return_train_score=True, verbose=4, n_jobs=3)\n",
    "search.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 3.11932492,  3.09468063,  3.88210638,  6.33453067, 23.2832106 ,\n",
       "        42.13535802,  3.27311118,  3.03968771,  3.28887971,  4.35198983,\n",
       "         4.96050763, 14.33884764,  3.83869608,  3.09853538,  4.58223295,\n",
       "         4.55477913,  7.70102318, 21.48735515,  1.5271457 ,  2.92117492,\n",
       "         6.75823243, 17.92416128, 41.67616073, 68.18525942,  1.9107457 ,\n",
       "         4.10255361,  9.1273183 , 23.72158734, 24.43632499, 16.86052815,\n",
       "         2.88715235,  2.73964373,  6.57039841, 10.98808996, 21.01670464,\n",
       "        25.69916821,  1.92987569,  1.78623025,  2.22022096,  2.36539666,\n",
       "         6.29528904, 19.12512668,  0.66204866,  1.42757575,  2.69754926,\n",
       "         3.73380502,  5.88949633, 35.25627947,  1.79704698,  1.35481675,\n",
       "         2.29301866,  3.4771502 , 10.39745498, 26.29678742]),\n",
       " 'std_fit_time': array([1.73071106, 1.28591816, 0.37357458, 0.70045591, 6.30986761,\n",
       "        6.24130006, 1.5577388 , 1.10930243, 2.34424124, 2.3118937 ,\n",
       "        1.00371797, 1.95959741, 0.55166902, 0.82542489, 3.26643486,\n",
       "        2.26926093, 0.71842701, 3.81444757, 0.79308906, 1.01103156,\n",
       "        1.20509897, 0.17351846, 0.49358183, 6.74481387, 0.50949785,\n",
       "        1.15779141, 1.10582572, 2.0347128 , 4.82900411, 1.28331907,\n",
       "        0.79854292, 0.59455619, 2.13950317, 2.38771273, 0.98686374,\n",
       "        1.39524494, 0.9826221 , 0.80428414, 0.11249514, 1.24762738,\n",
       "        1.36694661, 4.81693742, 0.08077624, 0.54650715, 0.58306695,\n",
       "        1.1640663 , 0.39805493, 9.55636596, 0.75520458, 0.59008567,\n",
       "        0.69889985, 0.05820158, 1.61258241, 2.33964752]),\n",
       " 'mean_score_time': array([0.00566292, 0.00790493, 0.00981935, 0.01493589, 0.02985096,\n",
       "        0.06346472, 0.00620588, 0.00752544, 0.01072232, 0.02336852,\n",
       "        0.04076036, 0.09341311, 0.00670338, 0.00696365, 0.01394796,\n",
       "        0.02601178, 0.07221071, 0.13638695, 0.004064  , 0.00742213,\n",
       "        0.00822997, 0.01473729, 0.03139528, 0.0728817 , 0.00511726,\n",
       "        0.00754499, 0.01293135, 0.02958894, 0.05078046, 0.13073063,\n",
       "        0.0079217 , 0.00972803, 0.01816241, 0.02914159, 0.07953699,\n",
       "        0.21556894, 0.00371329, 0.00518767, 0.00716901, 0.01065962,\n",
       "        0.02154867, 0.05273207, 0.00546606, 0.00449959, 0.00878572,\n",
       "        0.01451008, 0.03248564, 0.07714462, 0.00682839, 0.00765045,\n",
       "        0.00985527, 0.01586405, 0.04187481, 0.08415532]),\n",
       " 'std_score_time': array([2.15564197e-03, 1.02786528e-03, 2.28934996e-03, 2.22640716e-03,\n",
       "        2.15117864e-03, 4.31586441e-03, 1.79957363e-03, 9.24490742e-04,\n",
       "        1.17168650e-03, 2.05531789e-03, 4.04437892e-03, 6.63163071e-03,\n",
       "        7.62875177e-04, 5.26735418e-05, 2.24955641e-03, 7.69625522e-04,\n",
       "        1.74588849e-02, 1.02028695e-02, 6.55750132e-04, 1.84225871e-04,\n",
       "        2.00444558e-03, 1.04144209e-03, 1.48958236e-03, 1.03313178e-02,\n",
       "        7.16815792e-04, 1.83130595e-03, 6.19664243e-04, 5.53446240e-03,\n",
       "        1.02972736e-03, 1.34896744e-02, 1.03111757e-03, 7.62783232e-04,\n",
       "        2.84664036e-03, 2.86469275e-03, 4.48701731e-03, 4.76508142e-02,\n",
       "        8.62215651e-04, 3.55504105e-04, 8.14975480e-05, 1.50468497e-03,\n",
       "        3.41172137e-03, 5.96216966e-03, 1.55456668e-03, 1.03698909e-03,\n",
       "        1.23319688e-03, 1.67666651e-03, 3.22917490e-03, 3.18586825e-03,\n",
       "        2.56989211e-03, 6.51516226e-04, 2.45617800e-03, 2.54101216e-03,\n",
       "        8.61901209e-04, 2.57780830e-02]),\n",
       " 'param_activation': masked_array(data=['logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_hidden_layer_sizes': masked_array(data=[(8, 8), (16, 16), (32, 32), (64, 64), (128, 128),\n",
       "                    (256, 256), (8, 8, 8), (16, 16, 16), (32, 32, 32),\n",
       "                    (64, 64, 64), (128, 128, 128), (256, 256, 256),\n",
       "                    (8, 8, 8, 8), (16, 16, 16, 16), (32, 32, 32, 32),\n",
       "                    (64, 64, 64, 64), (128, 128, 128, 128),\n",
       "                    (256, 256, 256, 256), (8, 8), (16, 16), (32, 32),\n",
       "                    (64, 64), (128, 128), (256, 256), (8, 8, 8),\n",
       "                    (16, 16, 16), (32, 32, 32), (64, 64, 64),\n",
       "                    (128, 128, 128), (256, 256, 256), (8, 8, 8, 8),\n",
       "                    (16, 16, 16, 16), (32, 32, 32, 32), (64, 64, 64, 64),\n",
       "                    (128, 128, 128, 128), (256, 256, 256, 256), (8, 8),\n",
       "                    (16, 16), (32, 32), (64, 64), (128, 128), (256, 256),\n",
       "                    (8, 8, 8), (16, 16, 16), (32, 32, 32), (64, 64, 64),\n",
       "                    (128, 128, 128), (256, 256, 256), (8, 8, 8, 8),\n",
       "                    (16, 16, 16, 16), (32, 32, 32, 32), (64, 64, 64, 64),\n",
       "                    (128, 128, 128, 128), (256, 256, 256, 256)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate_init': masked_array(data=[0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02,\n",
       "                    0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02,\n",
       "                    0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02,\n",
       "                    0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02,\n",
       "                    0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02,\n",
       "                    0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_iter': masked_array(data=[500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
       "                    'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
       "                    'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
       "                    'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
       "                    'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
       "                    'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
       "                    'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',\n",
       "                    'adam', 'adam', 'adam', 'adam', 'adam'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (8, 8),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (16, 16),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (32, 32),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (64, 64),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (128, 128),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (256, 256),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (8, 8, 8),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (16, 16, 16),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (32, 32, 32),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (64, 64, 64),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (128, 128, 128),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (256, 256, 256),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (8, 8, 8, 8),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (16, 16, 16, 16),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (32, 32, 32, 32),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (64, 64, 64, 64),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (128, 128, 128, 128),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': (256, 256, 256, 256),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (8, 8),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (16, 16),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (32, 32),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (64, 64),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (128, 128),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (256, 256),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (8, 8, 8),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (16, 16, 16),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (32, 32, 32),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (64, 64, 64),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (128, 128, 128),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (256, 256, 256),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (8, 8, 8, 8),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (16, 16, 16, 16),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (32, 32, 32, 32),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (64, 64, 64, 64),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (128, 128, 128, 128),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'hidden_layer_sizes': (256, 256, 256, 256),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (8, 8),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (16, 16),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (32, 32),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (64, 64),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (128, 128),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (256, 256),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (8, 8, 8),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (16, 16, 16),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (32, 32, 32),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (64, 64, 64),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (128, 128, 128),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (256, 256, 256),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (8, 8, 8, 8),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (16, 16, 16, 16),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (32, 32, 32, 32),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (64, 64, 64, 64),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (128, 128, 128, 128),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': (256, 256, 256, 256),\n",
       "   'learning_rate_init': 0.02,\n",
       "   'max_iter': 500,\n",
       "   'solver': 'adam'}],\n",
       " 'split0_test_r2': array([ 9.30671487e-01,  9.41743761e-01,  9.41829949e-01,  9.41918931e-01,\n",
       "         9.40595872e-01,  9.39990492e-01,  9.92138786e-01,  9.92458487e-01,\n",
       "         9.54667109e-01, -3.98255809e-03, -4.34989036e-03, -1.60569820e-03,\n",
       "         9.94985857e-01,  9.37784338e-01,  9.92525875e-01, -6.02989129e-05,\n",
       "        -1.22480724e-03, -1.26356571e-02,  9.81044760e-01,  9.93109227e-01,\n",
       "         9.96255380e-01,  9.98032691e-01,  9.95281082e-01,  9.85115633e-01,\n",
       "         9.91303782e-01,  9.90717995e-01,  9.93820347e-01,  9.97322724e-01,\n",
       "         8.66571251e-01, -1.11891025e-03,  9.94807639e-01,  9.45330725e-01,\n",
       "         9.96487747e-01,  8.25383723e-01,  9.22111887e-01, -7.84767902e-04,\n",
       "         9.89768502e-01,  9.97639249e-01,  9.93130794e-01,  9.95052437e-01,\n",
       "         9.94348032e-01,  9.94198532e-01,  9.44928259e-01,  9.84926658e-01,\n",
       "         9.74312677e-01,  9.80314257e-01,  9.83258265e-01,  9.84150873e-01,\n",
       "         9.54346535e-01,  9.84931669e-01,  9.90403276e-01,  9.79749978e-01,\n",
       "         9.88532872e-01,  8.95114216e-01]),\n",
       " 'split1_test_r2': array([ 9.92168392e-01,  9.47619824e-01,  9.43371413e-01,  9.41560383e-01,\n",
       "         9.39718465e-01,  9.38300071e-01,  9.45466217e-01,  9.44858303e-01,\n",
       "         9.43510708e-01,  9.37532232e-01,  1.34061900e-04, -1.23180420e-03,\n",
       "         9.91083095e-01,  9.53104531e-01, -4.96491957e-03, -5.74322004e-03,\n",
       "        -1.11872228e-03, -5.52472738e-05,  9.90553382e-01,  9.97909705e-01,\n",
       "         9.95015248e-01,  9.95727627e-01,  9.93968125e-01,  9.80802879e-01,\n",
       "         9.92943115e-01,  9.94018681e-01,  9.96219522e-01,  9.98421375e-01,\n",
       "         9.51096446e-01, -9.48659509e-04,  9.84807734e-01,  9.64014639e-01,\n",
       "         9.95084146e-01,  9.18946394e-01,  9.46242600e-01, -9.64540660e-04,\n",
       "         9.44054385e-01,  9.86731111e-01,  9.94375533e-01,  9.95346556e-01,\n",
       "         9.89782805e-01,  9.83112164e-01,  9.38341287e-01,  9.81581363e-01,\n",
       "         9.97332487e-01,  9.91417825e-01,  9.95095441e-01,  9.93292542e-01,\n",
       "         9.24468570e-01,  9.85367190e-01,  9.86547885e-01,  9.89406350e-01,\n",
       "         9.91122147e-01,  9.23141941e-01]),\n",
       " 'split2_test_r2': array([ 9.41013063e-01,  9.50948869e-01,  9.41718096e-01,  9.41397791e-01,\n",
       "         9.40599028e-01,  9.40698829e-01,  9.95613152e-01,  9.70185993e-01,\n",
       "        -2.04214304e-03,  9.95592137e-04, -8.04688950e-04, -1.85103562e-03,\n",
       "         9.93060122e-01,  9.94072564e-01,  9.39247323e-01,  9.36766311e-01,\n",
       "        -4.38618986e-05, -1.96235008e-03,  9.93517431e-01,  9.90201509e-01,\n",
       "         9.98345476e-01,  9.97583800e-01,  9.98364300e-01,  9.90610090e-01,\n",
       "         9.89447875e-01,  9.96311764e-01,  9.95674470e-01,  9.98501361e-01,\n",
       "         9.48444388e-01, -7.82313938e-04,  9.89011249e-01,  9.95800259e-01,\n",
       "         9.70560774e-01,  9.86087295e-01,  9.46829008e-01, -1.68808957e-03,\n",
       "         9.93460531e-01,  9.87859540e-01,  9.94900706e-01,  9.97110359e-01,\n",
       "         9.90034825e-01,  9.86979661e-01,  9.91635093e-01,  9.89098605e-01,\n",
       "         9.93026332e-01,  9.95082278e-01,  9.94970099e-01,  9.81913558e-01,\n",
       "         9.50332281e-01,  9.11126366e-01,  9.78437752e-01,  9.89633690e-01,\n",
       "         9.72298184e-01,  9.93232130e-01]),\n",
       " 'mean_test_r2': array([ 9.54617647e-01,  9.46770818e-01,  9.42306486e-01,  9.41625702e-01,\n",
       "         9.40304455e-01,  9.39663131e-01,  9.77739385e-01,  9.69167594e-01,\n",
       "         6.32045225e-01,  3.11515089e-01, -1.67350580e-03, -1.56284601e-03,\n",
       "         9.93043025e-01,  9.61653811e-01,  6.42269426e-01,  3.10320931e-01,\n",
       "        -7.95797141e-04, -4.88441814e-03,  9.88371858e-01,  9.93740147e-01,\n",
       "         9.96538702e-01,  9.97114706e-01,  9.95871169e-01,  9.85509534e-01,\n",
       "         9.91231590e-01,  9.93682813e-01,  9.95238113e-01,  9.98081820e-01,\n",
       "         9.22037362e-01, -9.49961233e-04,  9.89542207e-01,  9.68381874e-01,\n",
       "         9.87377556e-01,  9.10139137e-01,  9.38394498e-01, -1.14579938e-03,\n",
       "         9.75761139e-01,  9.90743300e-01,  9.94135678e-01,  9.95836451e-01,\n",
       "         9.91388554e-01,  9.88096786e-01,  9.58301546e-01,  9.85202209e-01,\n",
       "         9.88223832e-01,  9.88938120e-01,  9.91107935e-01,  9.86452324e-01,\n",
       "         9.43049129e-01,  9.60475075e-01,  9.85129638e-01,  9.86263340e-01,\n",
       "         9.83984401e-01,  9.37162762e-01]),\n",
       " 'std_test_r2': array([2.68859428e-02, 3.80561990e-03, 7.54400490e-04, 2.17710346e-04,\n",
       "        4.14359289e-04, 1.00627526e-03, 2.28646139e-02, 1.94460319e-02,\n",
       "        4.48390610e-01, 4.42665633e-01, 1.93090463e-03, 2.54609665e-04,\n",
       "        1.59334156e-03, 2.37614358e-02, 4.58180368e-01, 4.42969852e-01,\n",
       "        5.33459440e-04, 5.53597562e-03, 5.32047419e-03, 3.17832431e-03,\n",
       "        1.37424110e-03, 9.97786461e-04, 1.84259602e-03, 4.01345372e-03,\n",
       "        1.42783857e-03, 2.29596289e-03, 1.02690974e-03, 5.37754363e-04,\n",
       "        3.92354045e-02, 1.37417952e-04, 4.09967170e-03, 2.08342351e-02,\n",
       "        1.19050584e-02, 6.59018731e-02, 1.15160337e-02, 3.90417339e-04,\n",
       "        2.24706695e-02, 4.89788531e-03, 7.42201555e-04, 9.08756816e-04,\n",
       "        2.09519440e-03, 4.59440691e-03, 2.37232804e-02, 3.07508006e-03,\n",
       "        9.99252750e-03, 6.27881674e-03, 5.55079079e-03, 4.92225079e-03,\n",
       "        1.32402527e-02, 3.48952599e-02, 4.98678309e-03, 4.60657703e-03,\n",
       "        8.33073962e-03, 4.12651494e-02]),\n",
       " 'rank_test_r2': array([34, 35, 37, 38, 39, 40, 27, 29, 46, 47, 53, 52, 10, 31, 45, 48, 49,\n",
       "        54, 17,  8,  3,  2,  4, 23, 12,  9,  6,  1, 43, 50, 15, 30, 20, 44,\n",
       "        41, 51, 28, 14,  7,  5, 11, 19, 33, 24, 18, 16, 13, 21, 36, 32, 25,\n",
       "        22, 26, 42], dtype=int32),\n",
       " 'split0_train_r2': array([ 9.32121206e-01,  9.42154170e-01,  9.42347813e-01,  9.42294088e-01,\n",
       "         9.40404264e-01,  9.40040547e-01,  9.92822991e-01,  9.92698610e-01,\n",
       "         9.55441797e-01, -3.84550052e-03, -4.36381872e-03, -1.52108118e-03,\n",
       "         9.95406718e-01,  9.39015587e-01,  9.93097770e-01, -9.14839894e-05,\n",
       "        -1.25140276e-03, -1.25602877e-02,  9.82180437e-01,  9.93553759e-01,\n",
       "         9.96552254e-01,  9.98190505e-01,  9.95597954e-01,  9.86058523e-01,\n",
       "         9.91619364e-01,  9.91147454e-01,  9.94180751e-01,  9.97537333e-01,\n",
       "         8.66628960e-01, -1.14526410e-03,  9.95032887e-01,  9.46082439e-01,\n",
       "         9.96770192e-01,  8.25893915e-01,  9.22945382e-01, -7.31960391e-04,\n",
       "         9.89879102e-01,  9.97735434e-01,  9.93241329e-01,  9.95373105e-01,\n",
       "         9.94597592e-01,  9.94566297e-01,  9.45685538e-01,  9.85689021e-01,\n",
       "         9.74960041e-01,  9.80810405e-01,  9.83733257e-01,  9.84949932e-01,\n",
       "         9.55508672e-01,  9.85271026e-01,  9.90586184e-01,  9.80407536e-01,\n",
       "         9.89077266e-01,  8.98228814e-01]),\n",
       " 'split1_train_r2': array([ 9.92143404e-01,  9.46693911e-01,  9.42452666e-01,  9.40400995e-01,\n",
       "         9.39938007e-01,  9.36722906e-01,  9.45135598e-01,  9.44176367e-01,\n",
       "         9.42790970e-01,  9.37331972e-01,  1.09715387e-04, -1.71342240e-03,\n",
       "         9.90930187e-01,  9.52425100e-01, -4.03268096e-03, -6.71253739e-03,\n",
       "        -1.56332270e-03, -9.11258767e-07,  9.90917034e-01,  9.97920431e-01,\n",
       "         9.95004558e-01,  9.95762395e-01,  9.94054810e-01,  9.81261326e-01,\n",
       "         9.92757674e-01,  9.94092921e-01,  9.96314468e-01,  9.98434371e-01,\n",
       "         9.52127090e-01, -9.71551685e-04,  9.84178811e-01,  9.64866640e-01,\n",
       "         9.95176109e-01,  9.17945956e-01,  9.46101313e-01, -1.39657853e-03,\n",
       "         9.43373610e-01,  9.86688942e-01,  9.94307485e-01,  9.95572973e-01,\n",
       "         9.89961548e-01,  9.83257385e-01,  9.37535216e-01,  9.82112506e-01,\n",
       "         9.97350233e-01,  9.91458627e-01,  9.95112100e-01,  9.93593722e-01,\n",
       "         9.22644077e-01,  9.85469192e-01,  9.86694221e-01,  9.89291817e-01,\n",
       "         9.91669965e-01,  9.24773424e-01]),\n",
       " 'split2_train_r2': array([ 9.42340666e-01,  9.51975750e-01,  9.42882354e-01,  9.42458378e-01,\n",
       "         9.41039230e-01,  9.41600944e-01,  9.95355307e-01,  9.69161007e-01,\n",
       "        -2.82636055e-03,  1.00396619e-03, -1.15444396e-03, -1.43088763e-03,\n",
       "         9.92586457e-01,  9.93673794e-01,  9.40082687e-01,  9.36787018e-01,\n",
       "        -7.25299683e-05, -2.56811816e-03,  9.93016251e-01,  9.89671868e-01,\n",
       "         9.98241889e-01,  9.97403681e-01,  9.98203976e-01,  9.90225521e-01,\n",
       "         9.88954205e-01,  9.96098291e-01,  9.95349995e-01,  9.98376301e-01,\n",
       "         9.47534313e-01, -1.16239619e-03,  9.88202002e-01,  9.95487184e-01,\n",
       "         9.69469129e-01,  9.85483254e-01,  9.46845991e-01, -2.24875943e-03,\n",
       "         9.93337272e-01,  9.87778904e-01,  9.94798761e-01,  9.96934840e-01,\n",
       "         9.89510926e-01,  9.86863878e-01,  9.91103200e-01,  9.89225710e-01,\n",
       "         9.92632580e-01,  9.94886360e-01,  9.94588400e-01,  9.81508758e-01,\n",
       "         9.50854827e-01,  9.10512023e-01,  9.77871914e-01,  9.89042167e-01,\n",
       "         9.72005002e-01,  9.92997106e-01]),\n",
       " 'mean_train_r2': array([ 9.55535092e-01,  9.46941277e-01,  9.42560945e-01,  9.41717820e-01,\n",
       "         9.40460500e-01,  9.39454799e-01,  9.77771299e-01,  9.68678661e-01,\n",
       "         6.31802136e-01,  3.11496813e-01, -1.80284910e-03, -1.55513040e-03,\n",
       "         9.92974454e-01,  9.61704827e-01,  6.43049259e-01,  3.09994332e-01,\n",
       "        -9.62418477e-04, -5.04310571e-03,  9.88704574e-01,  9.93715353e-01,\n",
       "         9.96599567e-01,  9.97118860e-01,  9.95952247e-01,  9.85848457e-01,\n",
       "         9.91110414e-01,  9.93779555e-01,  9.95281738e-01,  9.98116002e-01,\n",
       "         9.22096788e-01, -1.09307066e-03,  9.89137900e-01,  9.68812088e-01,\n",
       "         9.87138476e-01,  9.09774375e-01,  9.38630895e-01, -1.45909945e-03,\n",
       "         9.75529994e-01,  9.90734426e-01,  9.94115858e-01,  9.95960306e-01,\n",
       "         9.91356688e-01,  9.88229187e-01,  9.58107985e-01,  9.85675745e-01,\n",
       "         9.88314285e-01,  9.89051798e-01,  9.91144586e-01,  9.86684137e-01,\n",
       "         9.43002525e-01,  9.60417414e-01,  9.85050773e-01,  9.86247173e-01,\n",
       "         9.84250744e-01,  9.38666448e-01]),\n",
       " 'std_train_r2': array([2.62200397e-02, 4.01345660e-03, 2.31267109e-04, 9.33548232e-04,\n",
       "        4.51327656e-04, 2.03406645e-03, 2.31000702e-02, 1.98120590e-02,\n",
       "        4.48779832e-01, 4.42536714e-01, 1.88298500e-03, 1.17830349e-04,\n",
       "        1.84801491e-03, 2.32589035e-02, 4.58067628e-01, 4.43217601e-01,\n",
       "        6.42001911e-04, 5.41778902e-03, 4.69218850e-03, 3.36939966e-03,\n",
       "        1.32205805e-03, 1.01152428e-03, 1.71231563e-03, 3.66263047e-03,\n",
       "        1.59391911e-03, 2.03328090e-03, 8.72422500e-04, 4.09866436e-04,\n",
       "        3.92664686e-02, 8.62110697e-05, 4.48030270e-03, 2.03614359e-02,\n",
       "        1.25110525e-02, 6.54077996e-02, 1.10954989e-02, 6.20806723e-04,\n",
       "        2.27817844e-02, 4.97041791e-03, 6.50097295e-04, 6.93913712e-04,\n",
       "        2.29903674e-03, 4.71670250e-03, 2.35672103e-02, 2.90396850e-03,\n",
       "        9.63728635e-03, 5.99320434e-03, 5.24495982e-03, 5.08377756e-03,\n",
       "        1.45204310e-02, 3.52885329e-02, 5.31907623e-03, 4.13050465e-03,\n",
       "        8.72349977e-03, 3.99167418e-02]),\n",
       " 'split0_test_MSE': array([3.51440786e-04, 2.95313105e-04, 2.94876198e-04, 2.94425128e-04,\n",
       "        3.01131997e-04, 3.04200792e-04, 3.98501443e-05, 3.82295125e-05,\n",
       "        2.29801939e-04, 5.08939833e-03, 5.09126042e-03, 5.07734953e-03,\n",
       "        2.54177440e-05, 3.15384249e-04, 3.78879074e-05, 5.06951558e-03,\n",
       "        5.07541871e-03, 5.13326271e-03, 9.60880898e-05, 3.49307746e-05,\n",
       "        1.89822629e-05, 9.97270111e-06, 2.39211848e-05, 7.54519802e-05,\n",
       "        4.40829560e-05, 4.70524321e-05, 3.13259559e-05, 1.35716749e-05,\n",
       "        6.76378337e-04, 5.07488190e-03, 2.63211682e-05, 2.77130031e-04,\n",
       "        1.78043472e-05, 8.85166562e-04, 3.94831195e-04, 5.07318806e-03,\n",
       "        5.18656097e-05, 1.19671432e-05, 3.48214463e-05, 2.50802355e-05,\n",
       "        2.86510146e-05, 2.94088587e-05, 2.79170217e-04, 7.64099355e-05,\n",
       "        1.30214430e-04, 9.97911621e-05, 8.48673693e-05, 8.03425523e-05,\n",
       "        2.31426995e-04, 7.63845320e-05, 4.86478092e-05, 1.02651610e-04,\n",
       "        5.81292804e-05, 5.31688057e-04]),\n",
       " 'split1_test_MSE': array([3.99653663e-05, 2.67300526e-04, 2.88980528e-04, 2.98222373e-04,\n",
       "        3.07621835e-04, 3.14860024e-04, 2.78290568e-04, 2.81392804e-04,\n",
       "        2.88269695e-04, 3.18778369e-04, 5.10240152e-03, 5.10937166e-03,\n",
       "        4.55037279e-05, 2.39311597e-04, 5.12842206e-03, 5.13239380e-03,\n",
       "        5.10879459e-03, 5.10336758e-03, 4.82068987e-05, 1.06669519e-05,\n",
       "        2.54376158e-05, 2.18022834e-05, 3.07811751e-05, 9.79645547e-05,\n",
       "        3.60118890e-05, 3.05231810e-05, 1.92921018e-05, 8.05585717e-06,\n",
       "        2.49559024e-04, 5.10792674e-03, 7.75274343e-05, 1.83636379e-04,\n",
       "        2.50860248e-05, 4.13623491e-04, 2.74328615e-04, 5.10800779e-03,\n",
       "        2.85495266e-04, 6.77122778e-05, 2.87021351e-05, 2.37469236e-05,\n",
       "        5.21392219e-05, 8.61800711e-05, 3.14649692e-04, 9.39918806e-05,\n",
       "        1.36125477e-05, 4.37955733e-05, 2.50283844e-05, 3.42287322e-05,\n",
       "        3.85443358e-04, 7.46724832e-05, 6.86472934e-05, 5.40603018e-05,\n",
       "        4.53044462e-05, 3.92213258e-04]),\n",
       " 'split2_test_MSE': array([3.08192192e-04, 2.56280053e-04, 3.04508566e-04, 3.06182078e-04,\n",
       "        3.10355420e-04, 3.09833983e-04, 2.29201962e-05, 1.55770831e-04,\n",
       "        5.23542292e-03, 5.21955151e-03, 5.22895753e-03, 5.23442443e-03,\n",
       "        3.62591510e-05, 3.09693882e-05, 3.17417746e-04, 3.30380422e-04,\n",
       "        5.22498240e-03, 5.23500602e-03, 3.38698216e-05, 5.11946970e-05,\n",
       "        8.64447867e-06, 1.26240470e-05, 8.54612988e-06, 4.90599636e-05,\n",
       "        5.51322500e-05, 1.92701233e-05, 2.25998261e-05, 7.83001996e-06,\n",
       "        2.69365349e-04, 5.22884063e-03, 5.74135141e-05, 2.19426096e-05,\n",
       "        1.53812689e-04, 7.26904529e-05, 2.77805312e-04, 5.23357308e-03,\n",
       "        3.41671120e-05, 6.34309053e-05, 2.66425546e-05, 1.50976609e-05,\n",
       "        5.20655782e-05, 6.80280575e-05, 4.37045749e-05, 5.69570998e-05,\n",
       "        3.64356967e-05, 2.56938859e-05, 2.62799916e-05, 9.44971966e-05,\n",
       "        2.59501576e-04, 4.64342808e-04, 1.12657424e-04, 5.41614091e-05,\n",
       "        1.44735153e-04, 3.53604516e-05]),\n",
       " 'mean_test_MSE': array([2.33199448e-04, 2.72964562e-04, 2.96121764e-04, 2.99609860e-04,\n",
       "        3.06369751e-04, 3.09631600e-04, 1.13686969e-04, 1.58464382e-04,\n",
       "        1.91783152e-03, 3.54257607e-03, 5.14087316e-03, 5.14038187e-03,\n",
       "        3.57268743e-05, 1.95221745e-04, 1.82790924e-03, 3.51076327e-03,\n",
       "        5.13639857e-03, 5.15721211e-03, 5.93882700e-05, 3.22641412e-05,\n",
       "        1.76881191e-05, 1.47996772e-05, 2.10828299e-05, 7.41588328e-05,\n",
       "        4.50756984e-05, 3.22819121e-05, 2.44059613e-05, 9.81918400e-06,\n",
       "        3.98434237e-04, 5.13721642e-03, 5.37540389e-05, 1.60903006e-04,\n",
       "        6.55676868e-05, 4.57160169e-04, 3.15655041e-04, 5.13825631e-03,\n",
       "        1.23842663e-04, 4.77034421e-05, 3.00553787e-05, 2.13082734e-05,\n",
       "        4.42852716e-05, 6.12056624e-05, 2.12508161e-04, 7.57863053e-05,\n",
       "        6.00875581e-05, 5.64268738e-05, 4.53919151e-05, 6.96894937e-05,\n",
       "        2.92123976e-04, 2.05133274e-04, 7.66508421e-05, 7.02911070e-05,\n",
       "        8.27229598e-05, 3.19753922e-04]),\n",
       " 'std_test_MSE': array([1.37773166e-04, 1.64307793e-05, 6.40018572e-06, 4.89900061e-06,\n",
       "        3.86813227e-06, 4.35396572e-06, 1.16597353e-04, 9.92892676e-05,\n",
       "        2.34601281e-03, 2.28018839e-03, 6.24509070e-05, 6.77709695e-05,\n",
       "        8.20870172e-06, 1.20224483e-04, 2.33660336e-03, 2.24901678e-03,\n",
       "        6.41030859e-05, 5.63462505e-05, 2.66025753e-05, 1.66524819e-05,\n",
       "        6.91657283e-06, 5.06851584e-06, 9.29664823e-06, 1.99861440e-05,\n",
       "        7.83735518e-06, 1.14100547e-05, 5.07608804e-06, 2.65501305e-06,\n",
       "        1.96702423e-04, 6.61777219e-05, 2.10644130e-05, 1.05412712e-04,\n",
       "        6.24694109e-05, 3.33117536e-04, 5.60039846e-05, 6.88818715e-05,\n",
       "        1.14533786e-04, 2.53297563e-05, 3.47342470e-06, 4.42517119e-06,\n",
       "        1.10551300e-05, 2.36734935e-05, 1.20237782e-04, 1.51258153e-05,\n",
       "        5.04549809e-05, 3.15411255e-05, 2.79180377e-05, 2.57317922e-05,\n",
       "        6.69747502e-05, 1.83290152e-04, 2.67376175e-05, 2.28823685e-05,\n",
       "        4.41607153e-05, 2.09002455e-04]),\n",
       " 'rank_test_MSE': array([21, 20, 18, 17, 16, 15, 28, 26,  9,  7,  2,  3, 45, 24, 10,  8,  6,\n",
       "         1, 38, 47, 52, 53, 51, 32, 43, 46, 49, 54, 12,  5, 40, 25, 35, 11,\n",
       "        14,  4, 27, 41, 48, 50, 44, 36, 22, 31, 37, 39, 42, 34, 19, 23, 30,\n",
       "        33, 29, 13], dtype=int32),\n",
       " 'split0_train_MSE': array([3.50526396e-04, 2.98716122e-04, 2.97716148e-04, 2.97993588e-04,\n",
       "        3.07752647e-04, 3.09630881e-04, 3.70621068e-05, 3.77044089e-05,\n",
       "        2.30098757e-04, 5.18386262e-03, 5.18653922e-03, 5.17185931e-03,\n",
       "        2.37197265e-05, 3.14923780e-04, 3.56431473e-05, 5.16447687e-03,\n",
       "        5.17046669e-03, 5.22886582e-03, 9.20203014e-05, 3.32884189e-05,\n",
       "        1.78041777e-05, 9.34424032e-06, 2.27321854e-05, 7.19938512e-05,\n",
       "        4.32776426e-05, 4.57145881e-05, 3.00506290e-05, 1.27172215e-05,\n",
       "        6.88728644e-04, 5.16991859e-03, 2.56501932e-05, 2.78430522e-04,\n",
       "        1.66787448e-05, 8.99084598e-04, 3.97910392e-04, 5.16778429e-03,\n",
       "        5.22643632e-05, 1.16942305e-05, 3.49018096e-05, 2.38933054e-05,\n",
       "        2.78980610e-05, 2.80596657e-05, 2.80480121e-04, 7.39019614e-05,\n",
       "        1.29306459e-04, 9.90951516e-05, 8.40015311e-05, 7.77186190e-05,\n",
       "        2.29753415e-04, 7.60604854e-05, 4.86129861e-05, 1.01175570e-04,\n",
       "        5.64050473e-05, 5.25546857e-04]),\n",
       " 'split1_train_MSE': array([4.04377823e-05, 2.74365643e-04, 2.96195268e-04, 3.06755185e-04,\n",
       "        3.09138181e-04, 3.25686255e-04, 2.82386255e-04, 2.87323406e-04,\n",
       "        2.94454021e-04, 3.22551402e-04, 5.14642034e-03, 5.15580400e-03,\n",
       "        4.66821896e-05, 2.44867300e-04, 5.16774119e-03, 5.18153437e-03,\n",
       "        5.15503144e-03, 5.14698973e-03, 4.67498894e-05, 1.07035109e-05,\n",
       "        2.57114631e-05, 2.18108908e-05, 3.05998035e-05, 9.64476736e-05,\n",
       "        3.72761417e-05, 3.04036490e-05, 1.89693786e-05, 8.05826974e-06,\n",
       "        2.46401154e-04, 5.15198561e-03, 8.14314211e-05, 1.80830878e-04,\n",
       "        2.48284973e-05, 4.22330939e-04, 2.77415734e-04, 5.15417321e-03,\n",
       "        2.91455185e-04, 6.85118189e-05, 2.92992921e-05, 2.27858410e-05,\n",
       "        5.16677622e-05, 8.61739890e-05, 3.21505310e-04, 9.20666654e-05,\n",
       "        1.36383102e-05, 4.39623176e-05, 2.51579495e-05, 3.29730158e-05,\n",
       "        3.98149777e-04, 7.47898497e-05, 6.84846451e-05, 5.51148603e-05,\n",
       "        4.28745664e-05, 3.87190064e-04]),\n",
       " 'split2_train_MSE': array([2.93265438e-04, 2.44259719e-04, 2.90510318e-04, 2.92666738e-04,\n",
       "        2.99884771e-04, 2.97027793e-04, 2.36237186e-05, 1.56852501e-04,\n",
       "        5.10054996e-03, 5.08106825e-03, 5.09204630e-03, 5.09345234e-03,\n",
       "        3.77065726e-05, 3.21761896e-05, 3.04749916e-04, 3.21512263e-04,\n",
       "        5.08654349e-03, 5.09923649e-03, 3.55205671e-05, 5.25306814e-05,\n",
       "        8.94205956e-06, 1.32053300e-05, 9.13489095e-06, 4.97147065e-05,\n",
       "        5.61808425e-05, 1.98447709e-05, 2.36507357e-05, 8.25841866e-06,\n",
       "        2.66849643e-04, 5.09208674e-03, 6.00066763e-05, 2.29529715e-05,\n",
       "        1.55285340e-04, 7.38347042e-05, 2.70350570e-04, 5.09761218e-03,\n",
       "        3.38877983e-05, 6.21586271e-05, 2.64544081e-05, 1.55899372e-05,\n",
       "        5.33492628e-05, 6.68126075e-05, 4.52506805e-05, 5.47999218e-05,\n",
       "        3.74719820e-05, 2.60088648e-05, 2.75243434e-05, 9.40496849e-05,\n",
       "        2.49960932e-04, 4.55151473e-04, 1.12547309e-04, 5.57334499e-05,\n",
       "        1.42387447e-04, 3.56179391e-05]),\n",
       " 'mean_train_MSE': array([2.28076539e-04, 2.72447161e-04, 2.94807245e-04, 2.99138504e-04,\n",
       "        3.05591866e-04, 3.10781643e-04, 1.14357360e-04, 1.60626772e-04,\n",
       "        1.87503425e-03, 3.52916076e-03, 5.14166862e-03, 5.14037188e-03,\n",
       "        3.60361629e-05, 1.97322423e-04, 1.83604475e-03, 3.55584117e-03,\n",
       "        5.13734721e-03, 5.15836402e-03, 5.80969193e-05, 3.21742037e-05,\n",
       "        1.74859001e-05, 1.47868204e-05, 2.08222933e-05, 7.27187437e-05,\n",
       "        4.55782089e-05, 3.19876693e-05, 2.42235811e-05, 9.67796996e-06,\n",
       "        4.00659814e-04, 5.13799698e-03, 5.56960968e-05, 1.60738124e-04,\n",
       "        6.55975273e-05, 4.65083414e-04, 3.15225565e-04, 5.13985656e-03,\n",
       "        1.25869115e-04, 4.74548922e-05, 3.02185032e-05, 2.07563612e-05,\n",
       "        4.43050286e-05, 6.03487541e-05, 2.15745371e-04, 7.35895162e-05,\n",
       "        6.01389170e-05, 5.63554447e-05, 4.55612747e-05, 6.82471066e-05,\n",
       "        2.92621375e-04, 2.02000603e-04, 7.65483133e-05, 7.06746268e-05,\n",
       "        8.05556868e-05, 3.16118287e-04]),\n",
       " 'std_train_MSE': array([1.34724241e-04, 2.22730836e-05, 3.10117740e-06, 5.80828215e-06,\n",
       "        4.07497458e-06, 1.17280307e-05, 1.18940965e-04, 1.01941469e-04,\n",
       "        2.28093535e-03, 2.26780354e-03, 3.87226231e-05, 3.38183984e-05,\n",
       "        9.44850531e-06, 1.20227386e-04, 2.35842539e-03, 2.28702650e-03,\n",
       "        3.64721341e-05, 5.35286322e-05, 2.44215931e-05, 1.70940371e-05,\n",
       "        6.84977856e-06, 5.21089738e-06, 8.86646807e-06, 1.90855383e-05,\n",
       "        7.88739005e-06, 1.06205367e-05, 4.54199968e-06, 2.15062815e-06,\n",
       "        2.03866416e-04, 3.32787254e-05, 2.29756707e-05, 1.05261528e-04,\n",
       "        6.35060752e-05, 3.38260430e-04, 5.85381047e-05, 3.03837263e-05,\n",
       "        1.17327133e-04, 2.54192768e-05, 3.50935511e-06, 3.68108427e-06,\n",
       "        1.16217699e-05, 2.41613285e-05, 1.21715778e-04, 1.52156884e-05,\n",
       "        4.98673080e-05, 3.10976262e-05, 2.71985286e-05, 2.58182369e-05,\n",
       "        7.50744905e-05, 1.79005449e-04, 2.67166172e-05, 2.15689024e-05,\n",
       "        4.40692136e-05, 2.06229620e-04]),\n",
       " 'split0_test_MAPE': array([0.06632416, 0.07102397, 0.06916431, 0.06775692, 0.06946646,\n",
       "        0.0712802 , 0.02547835, 0.02611242, 0.06174378, 0.304525  ,\n",
       "        0.31894352, 0.30576967, 0.0201958 , 0.0627748 , 0.02475871,\n",
       "        0.31321205, 0.31462986, 0.32498651, 0.04274542, 0.02402582,\n",
       "        0.01685467, 0.01276537, 0.01958845, 0.03752412, 0.02910355,\n",
       "        0.03019377, 0.02352999, 0.01441278, 0.12619634, 0.31443068,\n",
       "        0.02104375, 0.05835659, 0.0170783 , 0.15362529, 0.0704803 ,\n",
       "        0.30711257, 0.02970959, 0.01398376, 0.02597249, 0.01942182,\n",
       "        0.02327061, 0.02245103, 0.07298586, 0.03566695, 0.05551814,\n",
       "        0.04577709, 0.04334676, 0.03721846, 0.06106392, 0.03678832,\n",
       "        0.02879537, 0.04671919, 0.03166382, 0.10558995]),\n",
       " 'split1_test_MAPE': array([0.02660244, 0.07142102, 0.07074673, 0.06591052, 0.07286301,\n",
       "        0.06583063, 0.06590575, 0.0685653 , 0.06978142, 0.07793752,\n",
       "        0.31727229, 0.31344493, 0.02885622, 0.06662817, 0.32556975,\n",
       "        0.30937592, 0.31379123, 0.31799316, 0.0312377 , 0.0132816 ,\n",
       "        0.02143443, 0.01884364, 0.02224095, 0.04313267, 0.02430929,\n",
       "        0.02455106, 0.01801066, 0.01153328, 0.07454122, 0.31738291,\n",
       "        0.03727121, 0.06502209, 0.02178967, 0.09405751, 0.06663284,\n",
       "        0.31386125, 0.06824294, 0.03317671, 0.02112328, 0.02013257,\n",
       "        0.03055826, 0.0391981 , 0.06537092, 0.0417573 , 0.01482406,\n",
       "        0.02874074, 0.01909749, 0.0246927 , 0.07023282, 0.03542959,\n",
       "        0.03458386, 0.03383361, 0.03046648, 0.09877773]),\n",
       " 'split2_test_MAPE': array([0.06596981, 0.06790848, 0.07130171, 0.06787118, 0.07176882,\n",
       "        0.0709595 , 0.01973545, 0.05621154, 0.32469175, 0.31738268,\n",
       "        0.32108695, 0.31332157, 0.02567112, 0.02213535, 0.0633167 ,\n",
       "        0.07808752, 0.31802077, 0.32337863, 0.02530587, 0.03081109,\n",
       "        0.01171901, 0.01436231, 0.01166247, 0.02928453, 0.03339981,\n",
       "        0.01843749, 0.0196685 , 0.01135709, 0.07568677, 0.32135833,\n",
       "        0.03184106, 0.01949716, 0.05907196, 0.03556235, 0.06112964,\n",
       "        0.32297174, 0.02320251, 0.03397683, 0.02162046, 0.01594139,\n",
       "        0.03148021, 0.0329183 , 0.0286717 , 0.03172007, 0.02546619,\n",
       "        0.02307054, 0.02146094, 0.04544888, 0.06755726, 0.10015717,\n",
       "        0.045655  , 0.03254059, 0.05424177, 0.02533078]),\n",
       " 'mean_test_MAPE': array([0.05296547, 0.07011782, 0.07040425, 0.06717954, 0.0713661 ,\n",
       "        0.06935678, 0.03703985, 0.05029642, 0.15207232, 0.23328174,\n",
       "        0.31910092, 0.31084539, 0.02490771, 0.05051277, 0.13788172,\n",
       "        0.2335585 , 0.31548062, 0.32211944, 0.03309633, 0.02270617,\n",
       "        0.01666937, 0.01532377, 0.01783062, 0.03664711, 0.02893755,\n",
       "        0.02439411, 0.02040305, 0.01243438, 0.09214144, 0.31772397,\n",
       "        0.03005201, 0.04762528, 0.03264664, 0.09441505, 0.06608093,\n",
       "        0.31464852, 0.04038501, 0.02704577, 0.02290541, 0.01849859,\n",
       "        0.02843636, 0.03152247, 0.05567616, 0.03638144, 0.03193613,\n",
       "        0.03252946, 0.02796839, 0.03578668, 0.06628466, 0.05745836,\n",
       "        0.03634474, 0.0376978 , 0.03879069, 0.07656615]),\n",
       " 'std_test_MAPE': array([0.01864204, 0.00157063, 0.00090557, 0.00089854, 0.00141557,\n",
       "        0.0024968 , 0.02054548, 0.01782887, 0.12210447, 0.1099703 ,\n",
       "        0.0015613 , 0.00358943, 0.00357657, 0.02012744, 0.13364574,\n",
       "        0.10994574, 0.0018285 , 0.00299064, 0.00723995, 0.00721696,\n",
       "        0.00396847, 0.00257289, 0.00449396, 0.00568739, 0.00371304,\n",
       "        0.00480076, 0.00231235, 0.00140079, 0.02408499, 0.00283846,\n",
       "        0.00674454, 0.02007487, 0.01878425, 0.04819965, 0.00383729,\n",
       "        0.00649837, 0.01987685, 0.00924201, 0.00217823, 0.00183135,\n",
       "        0.00367207, 0.00690783, 0.01934645, 0.00412871, 0.0172317 ,\n",
       "        0.00964927, 0.01091687, 0.00853394, 0.00384983, 0.03019771,\n",
       "        0.00699463, 0.00640089, 0.01093649, 0.03633547]),\n",
       " 'rank_test_MAPE': array([23, 16, 15, 18, 14, 17, 30, 25,  9,  8,  2,  6, 45, 24, 10,  7,  4,\n",
       "         1, 35, 48, 52, 53, 51, 31, 41, 46, 49, 54, 12,  3, 40, 26, 36, 11,\n",
       "        20,  5, 27, 44, 47, 50, 42, 39, 22, 32, 38, 37, 43, 34, 19, 21, 33,\n",
       "        29, 28, 13], dtype=int32),\n",
       " 'split0_train_MAPE': array([0.06565741, 0.07111639, 0.06908701, 0.06793365, 0.0705093 ,\n",
       "        0.07203981, 0.02500017, 0.02624437, 0.06210964, 0.31224195,\n",
       "        0.32580767, 0.31339177, 0.01977282, 0.06250196, 0.0243169 ,\n",
       "        0.32036436, 0.32170854, 0.33168479, 0.0419494 , 0.0237756 ,\n",
       "        0.01675512, 0.01247693, 0.01952918, 0.03723895, 0.02910193,\n",
       "        0.03000337, 0.0233564 , 0.01429544, 0.12888731, 0.32152057,\n",
       "        0.02116908, 0.05783253, 0.01681708, 0.15591785, 0.07097751,\n",
       "        0.31464595, 0.03047431, 0.01395598, 0.02649201, 0.01904252,\n",
       "        0.02321341, 0.02187797, 0.0734784 , 0.03545908, 0.05571469,\n",
       "        0.04578712, 0.04328412, 0.03718044, 0.06124137, 0.03688535,\n",
       "        0.02939059, 0.04688116, 0.03135032, 0.10490306]),\n",
       " 'split1_train_MAPE': array([0.02653463, 0.07135643, 0.07083301, 0.06606369, 0.0720849 ,\n",
       "        0.06618619, 0.06546926, 0.06841258, 0.06971989, 0.07742767,\n",
       "        0.31356971, 0.30956222, 0.02892311, 0.06609818, 0.32228081,\n",
       "        0.30537611, 0.30992144, 0.31432733, 0.03052623, 0.0132239 ,\n",
       "        0.02138823, 0.01873157, 0.02199712, 0.0423397 , 0.02456475,\n",
       "        0.02453964, 0.01788508, 0.01142326, 0.07370958, 0.31366367,\n",
       "        0.0379941 , 0.06380329, 0.02160422, 0.09477171, 0.0658884 ,\n",
       "        0.30999459, 0.06812219, 0.03324357, 0.02114165, 0.01967749,\n",
       "        0.03038777, 0.03894429, 0.0649154 , 0.04107154, 0.01477576,\n",
       "        0.02845542, 0.01921737, 0.02431809, 0.07077095, 0.03557723,\n",
       "        0.03445161, 0.03419527, 0.0292513 , 0.0978605 ]),\n",
       " 'split2_train_MAPE': array([0.06546601, 0.06701186, 0.07060426, 0.06717058, 0.07113407,\n",
       "        0.07004807, 0.01979447, 0.05575364, 0.32111316, 0.31374541,\n",
       "        0.31750299, 0.30958068, 0.0262592 , 0.02247135, 0.06306818,\n",
       "        0.07776056, 0.31438561, 0.31979827, 0.02554979, 0.03127253,\n",
       "        0.01180783, 0.01445801, 0.0118265 , 0.02956666, 0.03353241,\n",
       "        0.0183226 , 0.01999596, 0.01147846, 0.0758314 , 0.31777735,\n",
       "        0.03246718, 0.01976979, 0.05888034, 0.03585792, 0.06139364,\n",
       "        0.31939406, 0.0234387 , 0.03320653, 0.02150873, 0.01601764,\n",
       "        0.03186244, 0.032342  , 0.02910049, 0.03134992, 0.02530936,\n",
       "        0.02314163, 0.02185494, 0.04491226, 0.06688478, 0.09945765,\n",
       "        0.04509494, 0.03274206, 0.05378715, 0.02520911]),\n",
       " 'mean_train_MAPE': array([0.05255268, 0.06982823, 0.07017476, 0.06705597, 0.07124276,\n",
       "        0.06942469, 0.03675463, 0.05013686, 0.1509809 , 0.23447168,\n",
       "        0.31896012, 0.31084489, 0.02498504, 0.05035716, 0.1365553 ,\n",
       "        0.23450034, 0.31533853, 0.3219368 , 0.03267514, 0.02275735,\n",
       "        0.01665039, 0.01522217, 0.01778427, 0.03638177, 0.02906636,\n",
       "        0.02428854, 0.02041248, 0.01239905, 0.09280943, 0.31765386,\n",
       "        0.03054345, 0.0471352 , 0.03243388, 0.09551582, 0.06608651,\n",
       "        0.3146782 , 0.0406784 , 0.02680202, 0.02304746, 0.01824588,\n",
       "        0.02848787, 0.03105475, 0.05583143, 0.03596018, 0.03193327,\n",
       "        0.03246139, 0.02811881, 0.03547026, 0.06629903, 0.05730674,\n",
       "        0.03631238, 0.0379395 , 0.03812959, 0.07599089]),\n",
       " 'std_train_MAPE': array([0.0183977 , 0.00199388, 0.00077481, 0.0007677 , 0.00064781,\n",
       "        0.00243004, 0.02041522, 0.01766731, 0.12034179, 0.11104858,\n",
       "        0.00510126, 0.00180093, 0.00384271, 0.01977283, 0.13227721,\n",
       "        0.11100055, 0.00485901, 0.0072457 , 0.00686538, 0.00740342,\n",
       "        0.00391188, 0.00260999, 0.00433158, 0.00524968, 0.00366112,\n",
       "        0.00477196, 0.00225299, 0.00134114, 0.02552562, 0.00320875,\n",
       "        0.00700218, 0.01950319, 0.01880232, 0.04901709, 0.00391511,\n",
       "        0.00383739, 0.0196171 , 0.00908354, 0.00244027, 0.00159679,\n",
       "        0.00377789, 0.0070265 , 0.01922219, 0.00398462, 0.01735715,\n",
       "        0.00966921, 0.01077742, 0.00849406, 0.00391242, 0.02980998,\n",
       "        0.00654489, 0.00635048, 0.01110468, 0.03602306]),\n",
       " 'split0_test_MAE': array([0.01324111, 0.01338551, 0.01306617, 0.01279416, 0.01304948,\n",
       "        0.01336735, 0.00467   , 0.00462568, 0.01163861, 0.05877771,\n",
       "        0.05924785, 0.05876447, 0.00362712, 0.01234641, 0.00440942,\n",
       "        0.05897558, 0.05904591, 0.05960625, 0.00837163, 0.00447523,\n",
       "        0.00307916, 0.0025129 , 0.00365412, 0.0071514 , 0.00557343,\n",
       "        0.00579919, 0.00431527, 0.00253529, 0.02350841, 0.05903731,\n",
       "        0.0038768 , 0.01205945, 0.00307933, 0.02591848, 0.01436934,\n",
       "        0.05879219, 0.00568609, 0.00270315, 0.00507534, 0.00383168,\n",
       "        0.00438505, 0.00422899, 0.01354261, 0.00659201, 0.01065561,\n",
       "        0.00911726, 0.00824894, 0.00756806, 0.01150062, 0.00720766,\n",
       "        0.00557208, 0.00893661, 0.00647358, 0.02229575]),\n",
       " 'split1_test_MAE': array([0.00475817, 0.01316069, 0.0131421 , 0.01251618, 0.01335341,\n",
       "        0.01273406, 0.01226362, 0.01277592, 0.01299606, 0.01423688,\n",
       "        0.05925636, 0.0592386 , 0.00552853, 0.01229684, 0.05946484,\n",
       "        0.05928309, 0.05924109, 0.05926937, 0.00580286, 0.00235484,\n",
       "        0.0038947 , 0.00338867, 0.00405718, 0.00787325, 0.0042464 ,\n",
       "        0.00459722, 0.00315573, 0.00207252, 0.01378891, 0.05928689,\n",
       "        0.00715658, 0.01196084, 0.00403118, 0.0187877 , 0.0124616 ,\n",
       "        0.05923811, 0.0127301 , 0.00597334, 0.00405083, 0.00375161,\n",
       "        0.00596872, 0.00720264, 0.01266747, 0.00778229, 0.00281943,\n",
       "        0.00522988, 0.00366203, 0.00459759, 0.01441574, 0.00650319,\n",
       "        0.00648713, 0.00586966, 0.00572631, 0.01876265]),\n",
       " 'split2_test_MAE': array([0.01259953, 0.01260949, 0.01330814, 0.01274762, 0.01329644,\n",
       "        0.01320754, 0.00350172, 0.01044538, 0.06007658, 0.05986131,\n",
       "        0.05997495, 0.05985153, 0.00454987, 0.00396769, 0.01233922,\n",
       "        0.01448516, 0.05990088, 0.06004902, 0.00483595, 0.0058586 ,\n",
       "        0.00215476, 0.00270612, 0.00219422, 0.00521495, 0.0063062 ,\n",
       "        0.00341454, 0.00340033, 0.00205091, 0.01387448, 0.05997904,\n",
       "        0.00555796, 0.00345551, 0.0111909 , 0.00615081, 0.01176359,\n",
       "        0.06003361, 0.00455808, 0.00629259, 0.00418408, 0.00306188,\n",
       "        0.00600302, 0.00608944, 0.00547755, 0.0060869 , 0.00493756,\n",
       "        0.00401133, 0.00382616, 0.0084183 , 0.01250981, 0.01821436,\n",
       "        0.00837121, 0.00614122, 0.01117088, 0.00495562]),\n",
       " 'mean_test_MAE': array([0.0101996 , 0.0130519 , 0.01317214, 0.01268599, 0.01323311,\n",
       "        0.01310298, 0.00681178, 0.00928233, 0.02823708, 0.04429196,\n",
       "        0.05949305, 0.05928487, 0.00456851, 0.00953698, 0.02540449,\n",
       "        0.04424794, 0.05939596, 0.05964155, 0.00633681, 0.00422956,\n",
       "        0.00304288, 0.00286923, 0.00330184, 0.00674653, 0.00537535,\n",
       "        0.00460365, 0.00362377, 0.00221957, 0.01705727, 0.05943441,\n",
       "        0.00553045, 0.0091586 , 0.00610047, 0.01695233, 0.01286484,\n",
       "        0.05935464, 0.00765809, 0.00498969, 0.00443675, 0.00354839,\n",
       "        0.00545226, 0.00584036, 0.01056254, 0.0068204 , 0.00613753,\n",
       "        0.00611949, 0.00524571, 0.00686132, 0.01280872, 0.01064174,\n",
       "        0.00681014, 0.00698249, 0.00779026, 0.015338  ]),\n",
       " 'std_test_MAE': array([0.00385658, 0.00032602, 0.00010104, 0.00012156, 0.00013191,\n",
       "        0.0002689 , 0.00388443, 0.00342745, 0.02252074, 0.02125676,\n",
       "        0.00034077, 0.00044499, 0.00077636, 0.00393813, 0.0243009 ,\n",
       "        0.02104584, 0.00036582, 0.00031926, 0.001492  , 0.00144091,\n",
       "        0.00071079, 0.00037568, 0.00080031, 0.00112237, 0.0008525 ,\n",
       "        0.00097354, 0.00049905, 0.00022342, 0.00456178, 0.00039836,\n",
       "        0.0013391 , 0.0040329 , 0.00362039, 0.0081738 , 0.00110134,\n",
       "        0.00051346, 0.0036159 , 0.00162207, 0.00045482, 0.00034556,\n",
       "        0.00075477, 0.0012267 , 0.00361334, 0.00071073, 0.00330972,\n",
       "        0.00217733, 0.00212466, 0.0016379 , 0.00120872, 0.00536237,\n",
       "        0.00116534, 0.00138621, 0.00240985, 0.00748181]),\n",
       " 'rank_test_MAE': array([23, 17, 15, 20, 14, 16, 32, 25,  9,  7,  2,  6, 46, 24, 10,  8,  4,\n",
       "         1, 35, 48, 52, 53, 51, 34, 42, 45, 49, 54, 11,  3, 40, 26, 38, 12,\n",
       "        18,  5, 28, 44, 47, 50, 41, 39, 22, 31, 36, 37, 43, 30, 19, 21, 33,\n",
       "        29, 27, 13], dtype=int32),\n",
       " 'split0_train_MAE': array([0.01314237, 0.01333605, 0.01300061, 0.01277047, 0.01310834,\n",
       "        0.01341707, 0.00451971, 0.00457319, 0.01161322, 0.05958521,\n",
       "        0.05980595, 0.05954506, 0.00350191, 0.01224885, 0.00427007,\n",
       "        0.05961995, 0.05966838, 0.0601058 , 0.00822741, 0.00439552,\n",
       "        0.00299936, 0.00243495, 0.00357008, 0.00706582, 0.00554609,\n",
       "        0.00573757, 0.00424344, 0.00248777, 0.02374592, 0.05966307,\n",
       "        0.00384334, 0.01198674, 0.00301523, 0.02602081, 0.01442694,\n",
       "        0.05954706, 0.00574878, 0.00267041, 0.00510602, 0.00371721,\n",
       "        0.00432375, 0.00411145, 0.01348173, 0.00649636, 0.01064318,\n",
       "        0.00909385, 0.00819656, 0.0075071 , 0.0114081 , 0.00716413,\n",
       "        0.00559954, 0.00890586, 0.00639826, 0.02214059]),\n",
       " 'split1_train_MAE': array([0.004784  , 0.01324798, 0.01324202, 0.01258758, 0.01336589,\n",
       "        0.01283265, 0.01228755, 0.01284524, 0.01307271, 0.01427613,\n",
       "        0.05937471, 0.05930797, 0.0055706 , 0.01233231, 0.05969254,\n",
       "        0.05931568, 0.05931415, 0.05939745, 0.0057402 , 0.00236918,\n",
       "        0.00390139, 0.00339766, 0.00405146, 0.00780425, 0.00430539,\n",
       "        0.00460452, 0.00313965, 0.00207305, 0.0137763 , 0.05940261,\n",
       "        0.00730107, 0.01189158, 0.00403252, 0.01897165, 0.01246456,\n",
       "        0.05931207, 0.01277279, 0.006034  , 0.00409233, 0.00371878,\n",
       "        0.00595553, 0.00722411, 0.0126408 , 0.00773693, 0.00284365,\n",
       "        0.00520932, 0.00366694, 0.00454281, 0.01449133, 0.00658974,\n",
       "        0.00651121, 0.00595647, 0.00555287, 0.01867222]),\n",
       " 'split2_train_MAE': array([0.01250171, 0.01246757, 0.01318336, 0.0126211 , 0.01317706,\n",
       "        0.01304633, 0.00354875, 0.01035122, 0.05928758, 0.05904377,\n",
       "        0.05917719, 0.05900133, 0.00465553, 0.00403447, 0.01230659,\n",
       "        0.01443703, 0.05908503, 0.05925683, 0.00490702, 0.00592761,\n",
       "        0.00218518, 0.00274313, 0.00222875, 0.00528977, 0.00636253,\n",
       "        0.00341895, 0.00347494, 0.00208696, 0.01386871, 0.05918254,\n",
       "        0.00567344, 0.00351683, 0.01119434, 0.00622592, 0.01174491,\n",
       "        0.05924119, 0.00461075, 0.00616849, 0.00418007, 0.00310642,\n",
       "        0.00603805, 0.00599574, 0.00560343, 0.0059839 , 0.0049259 ,\n",
       "        0.0040204 , 0.00390728, 0.00832849, 0.01241395, 0.01805886,\n",
       "        0.00832384, 0.00618057, 0.01108139, 0.00497988]),\n",
       " 'mean_train_MAE': array([0.01014269, 0.0130172 , 0.01314199, 0.01265972, 0.0132171 ,\n",
       "        0.01309868, 0.00678534, 0.00925655, 0.02799117, 0.0443017 ,\n",
       "        0.05945261, 0.05928479, 0.00457601, 0.00953855, 0.02542307,\n",
       "        0.04445755, 0.05935585, 0.05958669, 0.00629154, 0.00423077,\n",
       "        0.00302864, 0.00285858, 0.00328343, 0.00671994, 0.00540467,\n",
       "        0.00458701, 0.00361934, 0.00221593, 0.01713031, 0.05941607,\n",
       "        0.00560595, 0.00913172, 0.0060807 , 0.01707279, 0.0128788 ,\n",
       "        0.05936677, 0.00771077, 0.00495763, 0.00445947, 0.00351414,\n",
       "        0.00543911, 0.0057771 , 0.01057532, 0.00673906, 0.00613757,\n",
       "        0.00610786, 0.00525693, 0.0067928 , 0.01277112, 0.01060424,\n",
       "        0.00681153, 0.0070143 , 0.0076775 , 0.01526423]),\n",
       " 'std_train_MAE': array([3.79818613e-03, 3.90307792e-04, 1.02805514e-04, 7.95039948e-05,\n",
       "        1.08890332e-04, 2.41440386e-04, 3.91079578e-03, 3.46462234e-03,\n",
       "        2.21379250e-02, 2.12324363e-02, 2.62533402e-04, 2.22584360e-04,\n",
       "        8.46410700e-04, 3.89211599e-03, 2.44532738e-02, 2.12280766e-02,\n",
       "        2.39971505e-04, 3.71525511e-04, 1.41048827e-03, 1.45738623e-03,\n",
       "        7.00949536e-04, 4.01414055e-04, 7.71229261e-04, 1.05526235e-03,\n",
       "        8.45759600e-04, 9.46651449e-04, 4.62043722e-04, 1.92309299e-04,\n",
       "        4.67809625e-03, 1.96405601e-04, 1.41241950e-03, 3.97051209e-03,\n",
       "        3.63966246e-03, 8.19201397e-03, 1.13343815e-03, 1.30727730e-04,\n",
       "        3.60941144e-03, 1.61824494e-03, 4.58580477e-04, 2.88300639e-04,\n",
       "        7.89396131e-04, 1.28010647e-03, 3.53237896e-03, 7.35959049e-04,\n",
       "        3.29740188e-03, 2.16648582e-03, 2.08094829e-03, 1.62593769e-03,\n",
       "        1.28381006e-03, 5.27642155e-03, 1.13228069e-03, 1.34065876e-03,\n",
       "        2.43152787e-03, 7.40870085e-03])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'logistic',\n",
       " 'hidden_layer_sizes': (256, 256, 256, 256),\n",
       " 'learning_rate_init': 0.02,\n",
       " 'max_iter': 500,\n",
       " 'solver': 'adam'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005157212105318282"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13832, 5)\n",
      "r2:\n",
      "[0.99654136 0.99478643 0.99668479]\n",
      "MSE:\n",
      "[-2.37234072e-05 -1.14050635e-04 -2.29888087e-05]\n",
      "MAE:\n",
      "[-0.01280249 -0.00301259 -0.00295126]\n",
      "MAPE:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.00473464, -0.00349429, -0.0047904 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f'data_{model}_{Type}_{option}.csv')\n",
    "print(data.shape)\n",
    "\n",
    "x = data[['moneyness', 'tau', 'r', 'vol']]\n",
    "y = data['option price']\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=None, shuffle=True)\n",
    "\n",
    "# StdScaler = StandardScaler()\n",
    "# x_train = StdScaler.fit_transform(x_train)\n",
    "\n",
    "# StdScaler = StandardScaler()\n",
    "# x_test = StdScaler.fit_transform(x_test)\n",
    "\n",
    "MLP = MLPRegressor(hidden_layer_sizes=(32, 32, 32, 32), activation='relu', solver='adam', batch_size=1024, learning_rate_init=0.005, max_iter=500, tol=1e-10, shuffle=True, verbose=False, validation_fraction=0.1)\n",
    "# MLP.fit(x_train, y_train)\n",
    "# score = MLP.score(x_test, y_test)\n",
    "# print(f'Type: {Type}, option: {option}, Model: {model}, ANN r2 = {score}')\n",
    "\n",
    "# r2\n",
    "print('r2:')\n",
    "print(cross_val_score(MLP, x, y, scoring='r2', cv=3))\n",
    "# MSE\n",
    "print('MSE:')\n",
    "print(cross_val_score(MLP, x, y, scoring='neg_mean_squared_error', cv=3))\n",
    "# MAE\n",
    "print('MAE:')\n",
    "print(cross_val_score(MLP, x, y, scoring='neg_mean_absolute_error', cv=3))\n",
    "# MAPE\n",
    "print('MAPE:')\n",
    "print(cross_val_score(MLP, x, y, scoring='neg_mean_absolute_error', cv=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('TBIC')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d61520230da68d3e97e097e1b1a3b83d1023192ac02a237b60a97cdc038f0e3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
